{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"Shan Gao\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"5711002\"\n",
    "STUDENT_1_NETID = \"samgao\"\n",
    "STUDENT_1_EMAIL = \"S.Gao-9@student.tudelft.nl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f04550e899e89ccc4ebeeadc13039165",
     "grade": false,
     "grade_id": "cell-60a0ce6bc7eb39ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1 - Vision-based angle prediction (42.5p)\n",
    "\n",
    "**Authors:** Tom√°s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "\n",
    "The following cells import all the necessary packages and external functions to properly run the code. Additionally, different dataset classes are created from the information gathered in the notebook 1a. Finally, different Pytorch data loaders will be created for each network architecture which will be introduced throughout the notebook where corresponds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\"\"\n",
    "# create directory for datasets\n",
    "datasets_dir = Path(\"datasets\")\n",
    "datasets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create directory for state dictionaries of neural network\n",
    "statedicts_dir = Path(\"statedicts\")\n",
    "statedicts_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThetaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = torch.tensor(dataset[\"th_pix_curr\"], dtype=torch.float32) / 255.0\n",
    "        self.y = torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class TrigDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        # y = [sin1 sin2 cos1 cos2]\n",
    "        self.x = torch.tensor(dataset[\"th_pix_curr\"], dtype=torch.float32) / 255.0\n",
    "        y_cos = torch.cos(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        y_sin = torch.sin(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        self.y = torch.cat((y_sin, y_cos), dim=-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.x = (\n",
    "            torch.tensor(\n",
    "                onp.transpose(dataset[\"th_pix_curr\"], (0, 3, 1, 2)), dtype=torch.float32\n",
    "            )\n",
    "            / 255.0\n",
    "        )\n",
    "        y_cos = torch.cos(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        y_sin = torch.sin(torch.tensor(dataset[\"th_curr_ss\"], dtype=torch.float32))\n",
    "        self.y = torch.cat((y_sin, y_cos), dim=-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        num_samples = self.x.shape[0]\n",
    "\n",
    "        return num_samples\n",
    "\n",
    "\n",
    "class SNNDataset(Dataset):\n",
    "    def __init__(self, path, num_itr, num_data):\n",
    "        self.path = path\n",
    "        self.num_itr = num_itr\n",
    "        self.num_data = num_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.num_itr * self.num_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < int(self.num_data * self.num_itr):\n",
    "            spike_path = \"spike\" + str(index) + \".pt\"\n",
    "            label_path = \"target\" + str(index) + \".pt\"\n",
    "            spike_out = torch.load(os.path.join(self.path, spike_path))\n",
    "            label_out = torch.load(os.path.join(self.path, label_path))\n",
    "            return spike_out, label_out\n",
    "        else:\n",
    "            raise IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_dataset_dataloader(\n",
    "    _filepath, _rng: random.KeyArray, _val_ratio=0.3, batch_size=64, model_type=\"theta\"\n",
    "):\n",
    "    assert 0.0 <= _val_ratio <= 1.0, \"Validation ratio needs to be in interval [0, 1].\"\n",
    "\n",
    "    _dataset = jnp.load(_filepath)\n",
    "    num_samples = _dataset[\"th_curr_ss\"].shape[0]\n",
    "\n",
    "    indices = jnp.arange(num_samples)\n",
    "    shuffled_indices = random.permutation(_rng, indices)\n",
    "    num_train_samples = int((1 - _val_ratio) * num_samples)\n",
    "    split_config = jnp.array(\n",
    "        [\n",
    "            num_train_samples,\n",
    "        ]\n",
    "    )\n",
    "    train_indices, val_indices = jnp.split(shuffled_indices, split_config)\n",
    "\n",
    "    _train_ds, _val_ds = {}, {}\n",
    "    for key, val in _dataset.items():\n",
    "        _train_ds[key] = val[train_indices]\n",
    "        _val_ds[key] = val[val_indices]\n",
    "\n",
    "    if model_type == \"theta\":\n",
    "        train_data = ThetaDataset(_train_ds)\n",
    "        val_data = ThetaDataset(_val_ds)\n",
    "    elif model_type == \"trig\":\n",
    "        train_data = TrigDataset(_dataset)\n",
    "        val_data = TrigDataset(_val_ds)\n",
    "    elif model_type == \"cnn\":\n",
    "        train_data = CNNDataset(_dataset)\n",
    "        val_data = CNNDataset(_val_ds)\n",
    "\n",
    "    _train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    _val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return _train_dataloader, _val_dataloader\n",
    "\n",
    "\n",
    "def load_test_dataset_dataloader(\n",
    "    _filepath, _rng: random.KeyArray, batch_size=64, model_type=\"theta\"\n",
    "):\n",
    "    _dataset = jnp.load(_filepath)\n",
    "    num_samples = _dataset[\"th_curr_ss\"].shape[0]\n",
    "\n",
    "    if model_type == \"theta\":\n",
    "        print(\"Theta Dataset\")\n",
    "        _data = ThetaDataset(_dataset)\n",
    "\n",
    "    elif model_type == \"trig\":\n",
    "        print(\"Trig Dataset\")\n",
    "        _data = TrigDataset(_dataset)\n",
    "    elif model_type == \"cnn\":\n",
    "        print(\"CNN dataset\")\n",
    "        _data = CNNDataset(_dataset)\n",
    "\n",
    "    _dataloader = torch.utils.data.DataLoader(\n",
    "        _data, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return _dataloader, _dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last function, evaluate_model, is also defined to evaluate the outcomes of the different models in their respective datasets and display a heatmap of the prediction errors. You do not have to worry about its workings nor interface since you are not required to use it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    _model, test_dataset, model=\"theta\", file=\"nothing.pdf\", num_bins: int = 10\n",
    "):\n",
    "    filepath = str(outputs_dir / file)\n",
    "    th = test_dataset[\"th_curr_ss\"]\n",
    "\n",
    "    # The pixel values need to be divided by 255.0 to match the input of the dataset classes\n",
    "    if model == \"cnn\":\n",
    "        x = onp.transpose(\n",
    "            onp.array(test_dataset[\"th_pix_curr\"] / 255.0, dtype=onp.float32),\n",
    "            (0, 3, 1, 2),\n",
    "        )\n",
    "        x = torch.tensor(x)\n",
    "        x_len = x.size()[0]\n",
    "        batch_size = 100\n",
    "        batch_num = int(int(x_len) / int(batch_size))\n",
    "        y_hat = torch.zeros((0, 4))\n",
    "        for i in range(batch_num):\n",
    "            x_batch = x[int(i * batch_size) : int((i + 1) * batch_size)]\n",
    "            y_batch = _model(x_batch).detach()\n",
    "            y_hat = torch.cat((y_hat, y_batch), dim=0)\n",
    "        y_hat = y_hat.numpy()\n",
    "    else:\n",
    "        y_hat = (\n",
    "            _model(\n",
    "                torch.tensor(\n",
    "                    onp.array(test_dataset[\"th_pix_curr\"] / 255.0, dtype=onp.float32)\n",
    "                )\n",
    "            )\n",
    "            .detach()\n",
    "            .numpy()\n",
    "        )  # need to convert back to np array\n",
    "\n",
    "    if model == \"theta\":\n",
    "        y = th\n",
    "    else:\n",
    "        y_cos = onp.cos(th)\n",
    "        y_sin = onp.sin(th)\n",
    "\n",
    "        y = onp.concatenate((y_sin, y_cos), axis=-1)\n",
    "\n",
    "        y = trig_to_theta_numpy(y)\n",
    "        y_hat = trig_to_theta_numpy(y_hat)\n",
    "\n",
    "    error = y_hat - y\n",
    "    error = onp.abs(error)\n",
    "\n",
    "    extent = onp.array(\n",
    "        [\n",
    "            [-onp.pi, onp.pi],\n",
    "            [-onp.pi, onp.pi],\n",
    "        ]\n",
    "    )\n",
    "    heatmap, xedges, yedges = onp.histogram2d(\n",
    "        x=th[:, 0], y=th[:, 1], bins=num_bins, range=extent\n",
    "    )\n",
    "\n",
    "    avg_bins = onp.zeros((num_bins, num_bins))\n",
    "    for i in range(avg_bins.shape[0]):\n",
    "        if i == 0:\n",
    "            # also include the left edge for the first bin\n",
    "            xcond = (xedges[i] <= th[:, 0]) & (th[:, 0] <= xedges[i + 1])\n",
    "        else:\n",
    "            xcond = (xedges[i] < th[:, 0]) & (th[:, 0] <= xedges[i + 1])\n",
    "\n",
    "        for j in range(avg_bins.shape[1]):\n",
    "            if j == 0:\n",
    "                # also include the left edge for the first bin\n",
    "                ycond = (yedges[j] <= th[:, 1]) & (th[:, 1] <= yedges[j + 1])\n",
    "            else:\n",
    "                ycond = (yedges[j] < th[:, 1]) & (th[:, 1] <= yedges[j + 1])\n",
    "\n",
    "            # combine condition for th1 and th2\n",
    "            bin_cond = xcond & ycond\n",
    "\n",
    "            # save the average error for each bin\n",
    "            avg_bins[i, j] = onp.mean(error[bin_cond, :])\n",
    "\n",
    "    print(\"Mean prediction error across bins:\", onp.mean(avg_bins))\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.imshow(avg_bins, extent=extent.flatten())\n",
    "    plt.title(\"Heatmap of prediction error\")\n",
    "    plt.xlabel(\"link 1 angles (rad)\")\n",
    "    plt.ylabel(\"link 2 angles (rad)\")\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.savefig(filepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def trig_to_theta(trig_data):\n",
    "    trig_len = trig_data.shape[0]\n",
    "    theta = torch.zeros(trig_len, 2)\n",
    "    for i in range(trig_len):\n",
    "        theta[i, 0] = torch.atan2(trig_data[i, 0], trig_data[i, 2])\n",
    "        theta[i, 1] = torch.atan2(trig_data[i, 1], trig_data[i, 3])\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "# Create a conversion function that supports numpy arrays instead of torch tensors\n",
    "def trig_to_theta_numpy(trig_data):\n",
    "    trig_len = trig_data.shape[0]\n",
    "    theta = onp.zeros((trig_len, 2))\n",
    "    for i in range(trig_len):\n",
    "        theta[i, 0] = onp.arctan2(trig_data[i, 0], trig_data[i, 2])\n",
    "        theta[i, 1] = onp.arctan2(trig_data[i, 1], trig_data[i, 3])\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for jax\n",
    "rng = random.PRNGKey(seed=42)\n",
    "rng, init_rng = random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4713f43e52cf23b0b368340cb88e19d4",
     "grade": false,
     "grade_id": "cell-ed9777984ea2045a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.1: Learn to predict angles (7.5p)\n",
    "\n",
    "We are going to create models that try to predict the link angles $\\hat{\\theta}$ given an image of the robot, so $\\theta \\approx \\hat{\\theta} =M(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Prepare data \n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into the 70/30 train/validation split, set the batch size to and put them in a dataloader. The data is first put in the class `ThetaDataset`. This class converts the `uint8` pixel values from a range of 0-255 to float values in the range `0-1`. The class also provides methods for the dataloader to retreive the pixel obervations `.x` and test labels `y`. The dataloader is set to Shuffle the data randomly before enumerating during the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta Dataset\n"
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_theta, val_loader_theta = load_training_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_train.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )\n",
    "    test_loader_theta, _ = load_test_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_test.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "894837df8e313f3c435880002725816d",
     "grade": false,
     "grade_id": "cell-d9964f8bdfdb040b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Create the model (1.5p)\n",
    "Here, create a PyTorch model class called NeuralNetworkTheta()\n",
    "- Start by flattening the input with `torch.nn.Flatten()`.\n",
    "- Then, add a fully connected hidden layer `torch.nn.Linear(...)` of 128 units and ReLU activation.\n",
    "- Finally, add a final fully connected linear layer `torch.nn.Linear(...)`without activation. The number of units must match the dimension of our target data, which is 2, as we try to predict the angles $\\theta_1$ and $\\theta_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c3764b0ee4465de155238df67983389",
     "grade": true,
     "grade_id": "cell-a14f93a12ba0f1a6",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of model parameters:  393602\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NN Model with Theta as the output\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" TASK 1.1: CREATE MODEL HERE \"\"\"\n",
    "\n",
    "\n",
    "class NeuralNetworkTheta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        input_size = 32*32*3\n",
    "        hiden_size = 128\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(input_size,hiden_size)\n",
    "        self.act_fn = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hiden_size, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n",
    "        \n",
    "\"\"\"TASK1.1: END\"\"\"\n",
    "model_theta = NeuralNetworkTheta()\n",
    "\n",
    "total_params_theta = sum(p.numel() for p in model_theta.parameters())\n",
    "print(\"total number of model parameters: \", total_params_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f058deeea9e14bada21355a98a90b119",
     "grade": false,
     "grade_id": "cell-c87a209ab1dddcd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Train the model (2p) \n",
    "\n",
    "Now that the model is defined, we can train it using the training dataset. We have a train-validation split of 0.3 and a batch size of 64 that is shuffled every epoch. Train the model for 100 epochs with the training data `train_loader_theta`. Tune the learning rate in the optimizer to give the best performance on the validation and test set over the 100 epochs. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_theta` using the function `evaluate_model_test_data_theta`. For each training loop, it would be useful to test the model performance on the valedation set to see if it is overfitting on the training data or whether it can generalize well. **hint:** \n",
    "- reduce the number of epochs and lower the number of runs to `1` while getting your model working and setting the optimal learning rate. \n",
    "- The try variying the the learning rate in the range of `1e-1` to `1e-5`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_theta.parameters(), lr=1e-3)\n",
    "# We choose the mean square loss as it is a regression problem\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_theta(_model, _test_loader):\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            batch = labels_test.shape[0]\n",
    "            est_th = _model(inputs_test)\n",
    "            loss_test = loss_fn(est_th, labels_test)\n",
    "            error_test = error_fn(est_th, labels_test)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "    return running_error_test / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db142cc8f7c612dcd25ccf3001742887",
     "grade": true,
     "grade_id": "cell-460ecb4435520c92",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bf4b916a184d9aa8e0816cac9ffd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1 finished\n",
      "Loss on test data: 1.028, Prediction error of model on test data: 0.637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621ce06175094c2cbe6e32af4d34e74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2 finished\n",
      "Loss on test data: 1.334, Prediction error of model on test data: 0.770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b8bff47c0e443f83f480154ea019e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3 finished\n",
      "Loss on test data: 1.296, Prediction error of model on test data: 0.721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c47e9f977834636b33d510cd89329b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4 finished\n",
      "Loss on test data: 1.598, Prediction error of model on test data: 0.880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987b0d883372408381f7ae786fc556ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5 finished\n",
      "Loss on test data: 0.983, Prediction error of model on test data: 0.614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc70853cf60474d982fc1eb0c3aca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 6 finished\n",
      "Loss on test data: 1.071, Prediction error of model on test data: 0.655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf510e66cf0410eb3a8ec34d6b88ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 7 finished\n",
      "Loss on test data: 1.415, Prediction error of model on test data: 0.769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233b018fe0d74b17b92082c572192821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 8 finished\n",
      "Loss on test data: 1.327, Prediction error of model on test data: 0.757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe538a7aefb4434bb97f8e3bed66b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 9 finished\n",
      "Loss on test data: 1.096, Prediction error of model on test data: 0.727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4935705b37c4a3c8c40e012c727e1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 10 finished\n",
      "Loss on test data: 1.277, Prediction error of model on test data: 0.697\n",
      "average prediction error:  0.7224702513124062\n"
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.1: TRAIN MODEL HERE\"\"\"\n",
    "\n",
    "    num_runs = 10  # Change to 1 until you get it to work once\n",
    "    pred_error_theta = onp.zeros((num_runs))\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # this code reinitializes the parameters of the model on each loop\n",
    "        model_theta = NeuralNetworkTheta()\n",
    "        optimizer = torch.optim.SGD(model_theta.parameters(), lr=1e-3)\n",
    "        # GPU\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_theta = model_theta.to(device)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        ## if the parameters of the model are initialized every run, it will not be useful\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            for i, data_train in enumerate(train_loader_theta):\n",
    "                inputs_train, labels_train = data_train[0].to(device), data_train[1].to(device)\n",
    "                est_th = model_theta(inputs_train)\n",
    "                loss = loss_fn(est_th, labels_train)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print(f\"run {run+1} finished\")\n",
    "        pred_error_theta[run] = evaluate_model_test_data_theta(\n",
    "            model_theta.to(\"cpu\"), test_loader_theta\n",
    "        )\n",
    "    print(\"average prediction error: \", onp.mean(pred_error_theta))\n",
    "    \"\"\"TASK 1.1: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb0a7add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data: 1.277, Prediction error of model on test data: 0.697\n"
     ]
    }
   ],
   "source": [
    "pred_error_theta = evaluate_model_test_data_theta(\n",
    "            model_theta, test_loader_theta\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5eac4dce1fd88aaf7cd4b8f5db0a1de",
     "grade": false,
     "grade_id": "cell-4126af15aa526be5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta Dataset\n",
      "Mean prediction error across bins: 0.6931683211627768\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If working on CodeSpaces, run this cell before running the next model to free up memory\n",
    "if not AUTOGRADING:\n",
    "    model_theta_scripted = torch.jit.script(model_theta)\n",
    "    model_theta_scripted.save(str(statedicts_dir / \"task_1-1_model_theta.pt\"))\n",
    "\n",
    "    _, test_dataset_theta = load_test_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_test.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )\n",
    "\n",
    "    evaluate_model(\n",
    "        model_theta,\n",
    "        test_dataset_theta,\n",
    "        model=\"theta\",\n",
    "        file=\"task_1-1_model_theta_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fb8bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel train_loader_theta\n",
    "%xdel val_loader_theta\n",
    "%xdel test_loader_theta\n",
    "%xdel model_theta_scripted\n",
    "\n",
    "%xdel model_theta\n",
    "%xdel test_dataset_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa4c2980ebf516a55e0a62a8bfc8d893",
     "grade": false,
     "grade_id": "cell-f481bd08fe4f5192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 - Analyse Model performance (4p)\n",
    "Analyze the prediction accuracy of the model on the test data from heat map of the loss outputted from the `evaluate_model` function. Where does this model have the lowest accuracy? What could be an explanation for the loss of accuracy in those regions? **2p** (Answer in the cell below)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50f464919ed852a42d638a59bf871076",
     "grade": true,
     "grade_id": "cell-f903416dd8d405dc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: (1) The yellower the heatmap, the larger the error. We can find that when link1's angle $\\in (1.9,2.5) \\vee (-3.14, -2.5)$ rad the error is the largest; *(2) One possible explanation is that in these region, the link2 has too much flexibility, the the simple model cannot predict well the link2's motion*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c233b9e1058b7cff5574c7eb9b58dc0",
     "grade": false,
     "grade_id": "cell-c2e81017b9edef72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In general, a separate test dataset is used to evaluate a trained model. Why? **(2p)** (Answer in the cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "130572e156ddb38d897477e74fb544bb",
     "grade": true,
     "grade_id": "cell-349b357d7c6f715f",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: Because the model should be tested on the data it has never seen to ensure the model can be applied to more general cases. The test set does not include the data from the train set, which can be used to show the generality of the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a88dea86fd1937b546e8f22b7b3bb51",
     "grade": false,
     "grade_id": "cell-9767cd0ad15daeab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.2: Indirectly predict the angle\n",
    "We are going to improve the accuracy by pre-processing the target data. Specifically, we will create a model $M_{trig}$ that learns to predict $\\sin(\\theta)$ and $\\cos(\\theta)$ for both links instead of directly predicting $\\theta$. Then, we can use the trigonometric relation to retrieve an estimate of $\\theta$ for both links.\n",
    "\n",
    "Note: In practice you would use the `atan2` implementation, as the regular arctangent only covers $[-\\frac{1}{2}\\pi, \\frac{1}{2}\\pi]$} $\\theta=\\arctan(\\frac{\\sin(\\theta)}{\\cos(\\theta)})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a04243746186bf36a665ae03c6280d7f",
     "grade": false,
     "grade_id": "cell-fed5df7188d95429",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Prepare the data (0p)\n",
    "\n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into the 70/30 train/validation split, set the batch size to and put them in a dataloader. The data is first put in the class `TrigDataset`. This class again converts the `uint8` pixel values from a range of 0-255 to float values in the range `0-1` while also calculating the values of $\\mathrm{sin}(\\theta_1), \\mathrm{sin}(\\theta_2), \\mathrm{cos}(\\theta_1), \\mathrm{cos}(\\theta_2)$ to be used as labels instead of just $\\theta_1, \\theta_2$ as was done in the `ThetaDataset` class. The dataloader is again set to shuffle the data randomly before enumerating during the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd12ec1bfaaf87dc40c3b627f9e49cad",
     "grade": false,
     "grade_id": "cell-7cae12728e42a5af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trig Dataset\n"
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_trig, val_loader_trig = load_training_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_train.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"trig\",\n",
    "    )\n",
    "    test_loader_trig, _ = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"trig\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cfc4df64e3fe110b4a91b531a3636b5",
     "grade": false,
     "grade_id": "cell-3fd3a8ee34be422f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Create the model (1.5p)\n",
    "\n",
    "Copy the model you created in Task 1.1. Change the number of hidden units of the final layer from 2 to 4. We do so, because we now want to predict two outputs ($\\sin(\\theta)$, $\\cos(\\theta)$) for both link angles, instead of only two outputs, $\\theta_1$ and $\\theta_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2972028186e367adfc65233eb66731d5",
     "grade": true,
     "grade_id": "cell-0e4c6601038f04b2",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of neural network parameters:  393860\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TASK 1.2: CREATE MODEL HERE \"\"\"\n",
    "\n",
    "\n",
    "class NeuralNetworkTrig(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        input_size = 32*32*3\n",
    "        hiden_size = 128\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(input_size,hiden_size)\n",
    "        self.act_fn = nn.ReLU()\n",
    "        # change the number of hidden layer output to 4\n",
    "        self.linear2 = nn.Linear(hiden_size, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n",
    "\"\"\"TASK1.2: END\"\"\"\n",
    "\n",
    "model_trig = NeuralNetworkTrig()\n",
    "total_params_trig = sum(p.numel() for p in model_trig.parameters())\n",
    "print(\"Total number of neural network parameters: \", total_params_trig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1978bc0990aa84c66211ea1c2b30e7d",
     "grade": false,
     "grade_id": "cell-8050878591ff79e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Train the model (2p)\n",
    "\n",
    "Now train a model with the same training parameters defined below as in task 1.1 but using the training data `train_loader_trig`. Tune the learning rate in the optimizer to give the best performance on the validation and test set over the 100 epochs. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_trig` using the function `evaluate_model_test_data_trig`. **Hint:** \n",
    "- reduce the number of epochs and lower the number of runs to `1` while getting your model working. \n",
    "- The try in the range `1e-1` to `1e-5` for the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_trig.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_trig(_model, _test_loader):\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            batch = labels_test.shape[0]\n",
    "            est = _model(inputs_test)\n",
    "            est_th = trig_to_theta(est)\n",
    "            label_th = trig_to_theta(labels_test)\n",
    "            loss_test = loss_fn(est_th, label_th)\n",
    "            error_test = error_fn(est_th, label_th)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "\n",
    "    return running_error_test / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "260b553bb242246ce25189399d31c569",
     "grade": true,
     "grade_id": "cell-68238795be7ee278",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f841e1daa4847b1a9ed48e71ab7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1 finished\n",
      "Loss on test data: 2.023, Prediction error of model on test data: 0.634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b3f68425ae43b19aeccd8d88d2ba58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2 finished\n",
      "Loss on test data: 1.898, Prediction error of model on test data: 0.593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ecdf1c0deb4cf09cf877d24d1efa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3 finished\n",
      "Loss on test data: 1.903, Prediction error of model on test data: 0.597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b728b946874dbd9cd0337a5d57b678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4 finished\n",
      "Loss on test data: 2.401, Prediction error of model on test data: 0.706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93de1516bb954b65997b4fb3edbac44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5 finished\n",
      "Loss on test data: 2.167, Prediction error of model on test data: 0.667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c853abb04548609d57a67b69df139c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 6 finished\n",
      "Loss on test data: 2.014, Prediction error of model on test data: 0.637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effcb6e5d7124664b78d89e0d576385a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 7 finished\n",
      "Loss on test data: 1.914, Prediction error of model on test data: 0.635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33f35f43fb94a3eb778922d26640332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 8 finished\n",
      "Loss on test data: 2.043, Prediction error of model on test data: 0.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caef5dbff36a415495f601433a1e9d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 9 finished\n",
      "Loss on test data: 2.296, Prediction error of model on test data: 0.683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b5b9b8c3b428e9d7b619aca009432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 10 finished\n",
      "Loss on test data: 2.114, Prediction error of model on test data: 0.642\n",
      "average prediction error:  0.6417030449457994\n"
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.2: TRAIN MODEL HERE\"\"\"\n",
    "    num_runs = 10\n",
    "    pred_error_trig = onp.zeros((num_runs))\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        model_trig = NeuralNetworkTrig()\n",
    "        optimizer = torch.optim.SGD(model_trig.parameters(), lr=1e-3)\n",
    "        # YOUR CODE HERE\n",
    "        # GPU\n",
    "        model_trig = model_trig\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            for i, data_train in enumerate(train_loader_trig):\n",
    "                inputs_train, labels_train = data_train[0], data_train[1]\n",
    "                est_th = model_trig(inputs_train)\n",
    "                loss = loss_fn(est_th, labels_train)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print(f\"run {run+1} finished\")\n",
    "        pred_error_trig[run] = evaluate_model_test_data_trig(\n",
    "            model_trig, test_loader_trig\n",
    "        )\n",
    "    print(\"average prediction error: \", onp.mean(pred_error_trig))\n",
    "    \"\"\"TASK 1.2: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d7b36b367c60424ae737ae1554d1042",
     "grade": false,
     "grade_id": "cell-537ac57da9947bb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trig Dataset\n",
      "Mean prediction error across bins: 0.6461418911970004\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If working on CodeSpaces, run this cell before running the next model to free up memory\n",
    "if not AUTOGRADING:\n",
    "    model_trig_scripted = torch.jit.script(model_trig)\n",
    "    model_trig_scripted.save(str(statedicts_dir / \"task_1-2_model_trig.pt\"))\n",
    "\n",
    "\n",
    "    _, test_dataset_trig = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"trig\",\n",
    "    )\n",
    "\n",
    "    evaluate_model(\n",
    "        model_trig,\n",
    "        test_dataset_trig,\n",
    "        model=\"trig\",\n",
    "        file=\"task_1-2_model_trig_prediction_error.pdf\",\n",
    "    )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91c48d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%xdel train_loader_trig\n",
    "%xdel val_loader_trig\n",
    "%xdel test_loader_trig\n",
    "%xdel model_trig_scripted\n",
    "\n",
    "%xdel test_dataset_trig\n",
    "%xdel model_trig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55f88a15dfd4da8210da2406d6deef76",
     "grade": false,
     "grade_id": "cell-f481bd08fe4f5191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 - Analyse Model performance (4p)\n",
    "Compare the prediction estimates for $M_{trig}$ with the plot for $M_Œ∏$. Why does indirectly predicting the angle improve the prediction accuracy? **(2p)** (Answer in the cell below)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76513491faa4e3f5053dcd14e473ffb3",
     "grade": true,
     "grade_id": "cell-2815ae8a80e8eb78",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: (1) Compared with the $M_{\\theta}$, $M_{trig}$ is much better for 2 reasons. First, the overall error is decreased; Second, the region with high error is more concentrated. (2) With 2 more output from the network, the sin($\\theta$) and cos($\\theta$) of the two links can be calculated which enable the network to get more information about the dynamics of the system since both of them contribute to the changing of $\\theta$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e152dc29dcb3582ed894bbcbe7703f07",
     "grade": false,
     "grade_id": "cell-dc170e69aa93f07f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why is it not sufficient to predict only sin(Œ∏) and use its inverse Œ∏ = arcsin(sin(Œ∏)) to get an estimate of the angle? **(2p)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a767cac6dceb52e46692aed13595d95",
     "grade": true,
     "grade_id": "cell-dae1ce5f27eb6216",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: For one value y, y=sin($\\theta$) may give two different $\\theta$ value, i.e. y = arcsin(x) is not a one-to-one mapping, then we need cos($\\theta$) and arctan(x) to uniquely determine the $\\theta$ value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dbfb868b40c0f2a45d220ec9ff0176d",
     "grade": false,
     "grade_id": "cell-eb4b321fb6188424",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.3: Indirectly predict the angles with a Convolutional Neural Network (10)\n",
    "Instead of using a vanilla fully-connected neural network, we will build a prediction model $M_{cnn}$ that uses a convolutional neural network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd426cbb8c61317823abac79e7e1e66a",
     "grade": false,
     "grade_id": "cell-505fc74a22f4805f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Prepare the data\n",
    "\n",
    "Run the functions below to load the data generated in `task_1a_generate_data.ipynb`, split the training into the 70/30 train/validation split, set the batch size to and put them in a dataloader. The data is first put in the class `CNNDataset`. This class again converts the `uint8` pixel values from a range of 0-255 to float values in the range `0-1` while also calculating the values of $\\mathrm{sin}(\\theta_1), \\mathrm{sin}(\\theta_2), \\mathrm{cos}(\\theta_1), \\mathrm{cos}(\\theta_2)$ to be used as labels instead of just $\\theta_1, \\theta_2$ as was done in the `ThetaDataset` class. We also permutate the order of the pixel ovbservations from `(number of samples, pixel rows, pixel columns, color channels)` to `(number of samples, color channels, pixel rows, pixel columns, )` as this is the order that the 2d convolution layer expects. The dataloader is again set to shuffle the data randomly before enumerating during the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b44964c85bb36d199843f1e42670568",
     "grade": false,
     "grade_id": "cell-ba0ddd02786cf10e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN dataset\n"
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_cnn, val_loader_cnn = load_training_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_train.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"cnn\",\n",
    "    )\n",
    "    test_loader_cnn, _ = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"cnn\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dd582b3dc962a5cfc28582618bf9fa7",
     "grade": false,
     "grade_id": "cell-44f9f0eecd679b24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Create the model (2p)\n",
    "Again, create sequential PyTorch model class and define the following architecture with Convolutional and pooling layers. \n",
    "- Start with a CNN layer `torch.nn.Conv2d(...)` with 32 filters, kernel size of `3x3` and a ReLU activation function.\n",
    "- Then add a max pooling layer `torch.nn.MaxPool2d(...)` with a pool size of `2x2`.\n",
    "- Add another convolutional layer with 10 filters and a ReLU activation function.\n",
    "- Then add another max pooling layer `torch.nn.MaxPool2d(...)` with a pool size of `2x2`.\n",
    "- Flatten the output of the pooling layer\n",
    "- Add a fully connected layer of 30 with a relu activation function.\n",
    "- Finally, add a fully connected layer without activation. Remember, the number of ouput units must match the dimension of the target data, which is 4 as we will predict the trigonometric function again. \n",
    "\n",
    "**note:* No zero padding is needed as the images have enough whitespace at the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9521a1b51f4f9d3769c716c3e6b515e",
     "grade": true,
     "grade_id": "cell-b5d85df96369ff97",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of model parameters:  17040\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TASK 1.3: CREATE MODEL HERE\"\"\"\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class NeuralNetworkCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,  32, 3)  #32*32*3 ->30*30*32\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2) #30*30*32 ->15*15*32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 10, 2) # 15*15*32 -> 14*14*10\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(10*7*7, 30)\n",
    "        self.linear2 = torch.nn.Linear(30, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        y = self.linear2(x)\n",
    "        return y\n",
    "\"\"\"TASK 1.3: END HERE\"\"\"\n",
    "\n",
    "model_cnn = NeuralNetworkCNN()\n",
    "total_params_cnn = sum(p.numel() for p in model_cnn.parameters())\n",
    "print(\"total number of model parameters: \", total_params_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "086f3d6a3395f08b5496fb734a64f6dd",
     "grade": false,
     "grade_id": "cell-ad3641dc5e865e94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Train the model (2p)\n",
    "\n",
    "Train the model with the same training parameters defined below as in task 1.1 and 1.2 but using the training data `train_loader_cnn`. Again, Tune the learning rate in the optimizer to give the best performance on the validation and test set over the 100 epochs. Do this 10 times and record the prediction error of the final model of each of the 10 runs on the test dataset `test_loader_cnn` using the function `evaluate_model_test_data_cnn`. Don't forget to reinitialize the parameters on each run! **Hints:** \n",
    "- reduce the number of epochs and lower the number of runs to `1` while getting your model working. \n",
    "- The try in the range of 1e-1 to 1e-5 for the learning rate\n",
    "\n",
    "#### One last thing!\n",
    "A Convolutional neural network that can predict angles is required for task 2b. Therefore, focus getting the perfect learning and optimal model accuracy with this Neural Network to see how far you can increase the prediction accuracy of link angles. Be warned, the accuracy of your model will affect the performance of you controller in task 2b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "error_fn = torch.nn.L1Loss()\n",
    "num_epochs = 100 #edit 100\n",
    "\n",
    "\n",
    "def evaluate_model_test_data_cnn(_model, _test_loader):\n",
    "    \"\"\"\n",
    "    evaluates the model_cnn on the\n",
    "    \"\"\"\n",
    "    running_loss_test = 0.0\n",
    "    running_error_test = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data_test in enumerate(_test_loader):\n",
    "            count += 1\n",
    "            inputs_test, labels_test = data_test\n",
    "            batch = labels_test.shape[0]\n",
    "            est = _model(inputs_test)\n",
    "            est_th = trig_to_theta(est)\n",
    "            label_th = trig_to_theta(labels_test)\n",
    "            loss_test = loss_fn(est_th, label_th)\n",
    "            error_test = error_fn(est_th, label_th)\n",
    "            running_loss_test += loss_test.item()\n",
    "            running_error_test += error_test.item()\n",
    "\n",
    "    print(\n",
    "        f\"Loss on test data: {running_loss_test / count:.3f}, Prediction error of model on test data: {running_error_test / count:.3f}\"\n",
    "    )\n",
    "    return running_error_test / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df16db6098f074e415110ffbd6f4cef8",
     "grade": true,
     "grade_id": "cell-cf838bf5bcf84bdb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samgao1999/anaconda3/envs/ics/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6e021acc7e4227ac94e2c23a6b384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1 finished\n",
      "Loss on test data: 1.695, Prediction error of model on test data: 0.535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79adfa362ac34ab99441bc1e05d24a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2 finished\n",
      "Loss on test data: 2.044, Prediction error of model on test data: 0.626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0623bba82ef4433922607288f80f16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3 finished\n",
      "Loss on test data: 1.855, Prediction error of model on test data: 0.579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa10a36acab4de081e3c7e670304052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m model_cnn \u001b[39m=\u001b[39m model_cnn\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mfor\u001b[39;00m i, data_train \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader_cnn):\n\u001b[1;32m     16\u001b[0m         inputs_train, labels_train \u001b[39m=\u001b[39m data_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), data_train[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m         est_th \u001b[39m=\u001b[39m model_cnn(inputs_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/ics/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ics/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ics/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/ics/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.3: TRAIN MODEL HERE\"\"\"\n",
    "\n",
    "    num_runs = 10 # edit 10\n",
    "    pred_error_cnn = onp.zeros((num_runs))    \n",
    "\n",
    "    for run in range(num_runs):\n",
    "        model_cnn = NeuralNetworkCNN()\n",
    "        optimizer = torch.optim.SGD(model_cnn.parameters(), lr=1e-3)\n",
    "        # YOUR CODE HERE\n",
    "        # GPU\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_cnn = model_cnn.to(device)\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            for i, data_train in enumerate(train_loader_cnn):\n",
    "                inputs_train, labels_train = data_train[0].to(device), data_train[1].to(device)\n",
    "                est_th = model_cnn(inputs_train)\n",
    "                loss = loss_fn(est_th, labels_train)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print(f\"run {run+1} finished\")\n",
    "        pred_error_cnn[run] = evaluate_model_test_data_cnn(model_cnn.to(\"cpu\"), test_loader_cnn)\n",
    "    print(\"average prediction error: \", onp.mean(pred_error_cnn))\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "    \"\"\"TASK 1.3: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6541c223531a25f6b244e920924e534",
     "grade": false,
     "grade_id": "cell-4f2f9c81324c39b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN dataset\n",
      "Mean prediction error across bins: 1.6177838327271032\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAHHCAYAAADNiDBWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMlUlEQVR4nO3deVwU9f8H8NeCspyLF4IoIqJ5i4pHYCYaiuhPpUOrrwUeqSlm3oqVR36Nyqu8tRK6TM08sjwiFY88MSgv8EgFUVQ8QFBBdub3h7FfdxeQdY/ZZV7Px2MeD+azn5l5Dyzw3s81ClEURRAREZEs2UkdABEREUmHiQAREZGMMREgIiKSMSYCREREMsZEgIiISMaYCBAREckYEwEiIiIZYyJAREQkY0wEiIiIZIyJAJFE5syZg/r168Pe3h6tWrWSOpwyzZgxAwqFQqusXr16GDhwoMmuMXDgQNSrV89k5yOi8mEiQACA+Ph4KBQKJCUllfh6SEgImjdvbtYYtm7dihkzZpj1Gtbit99+w6RJk9CxY0fExcXho48+kjoki7hy5QpmzJiBlJQUqUMhon9VkjoAomJbt27FkiVLZJEM7Nq1C3Z2dvjqq6/g4OAgdThPJS0tDXZ2hn2WuHLlCmbOnIl69erptYJ88cUXEATBhBESUXmwRYBIAtevX4eTk5PZk4AHDx6Y7Z+rUqlE5cqVTXa+ypUrQ6lUmux8liAIAh48eFDia/n5+Uaf/969e0afg+hJmAiQUb777jsEBgbCyckJ1apVw2uvvYaMjAytOvv27UO/fv1Qt25dKJVK+Pj4YOzYsbh//76mzsCBA7FkyRIAgEKh0GwAcPHiRSgUCsydOxdLlixB/fr14ezsjO7duyMjIwOiKGLWrFmoU6cOnJyc0LdvX9y6dUsrhs2bN6NXr17w9vaGUqmEv78/Zs2aBbVarVWvuAvk2LFjCA4OhpOTE/z8/LB8+fJyfT+Kioowa9Ys+Pv7Q6lUol69epg6dSoKCgo0dRQKBeLi4pCfn6+5z/j4+FLPWd6YEhMToVAosGbNGrz//vuoXbs2nJ2dkZubCwA4fPgwevToAXd3dzg7O6Nz5874448/9K63f/9+tGvXDo6OjvD398eKFStKjKukMQJ37tzB2LFjUa9ePSiVStSpUweRkZHIzs5GYmIi2rVrBwAYNGiQ3r2XNEYgPz8f48ePh4+PD5RKJRo1aoS5c+dC96GpCoUCo0aNwqZNm9C8eXMolUo0a9YM27dvL/X7+riCggJMnz4dDRo00LxHJ02apPVze/w633//PZo1awalUont27drutb27NmDkSNHombNmqhTp47muKVLl2rqe3t7Izo6Gnfu3NE69+M/5+effx7Ozs6YOnVqueInMga7BkhLTk4OsrOz9cofPnyoVzZ79mx88MEH6N+/P9566y3cuHEDixYtwvPPP4/k5GRUqVIFAPDjjz/i3r17GDFiBKpXr44jR45g0aJFuHz5Mn788UcAwPDhw3HlyhUkJCTg22+/LTG277//HoWFhXjnnXdw69YtfPrpp+jfvz+6du2KxMRETJ48GefOncOiRYswYcIErFq1SnNsfHw8XF1dMW7cOLi6umLXrl2YNm0acnNzMWfOHK3r3L59Gz179kT//v3x+uuvY926dRgxYgQcHBwwePDgMr9/b731Fr7++mu88sorGD9+PA4fPozY2FicPn0aGzduBAB8++23WLlyJY4cOYIvv/wSABAcHFzmeQ2JadasWXBwcMCECRNQUFAABwcH7Nq1C+Hh4QgMDMT06dNhZ2eHuLg4dO3aFfv27UP79u0BAMePH0f37t3h4eGBGTNmoKioCNOnT4enp2eZ8QFAXl4eOnXqhNOnT2Pw4MFo06YNsrOz8fPPP+Py5cto0qQJPvzwQ0ybNg3Dhg1Dp06dyrx3URTRp08f7N69G0OGDEGrVq2wY8cOTJw4EZmZmViwYIFW/f3792PDhg0YOXIk3NzcsHDhQrz88stIT09H9erVS41bEAT06dMH+/fvx7Bhw9CkSRMcP34cCxYswJkzZ7Bp0yat+rt27cK6deswatQo1KhRA/Xq1dOMeRg5ciQ8PDwwbdo0TYvAjBkzMHPmTISGhmLEiBFIS0vDsmXLcPToUfzxxx9arSo3b95EeHg4XnvtNbzxxhvl+r4TGU0kEkUxLi5OBFDm1qxZM039ixcvivb29uLs2bO1znP8+HGxUqVKWuX37t3Tu15sbKyoUCjES5cuacqio6PFkt6SFy5cEAGIHh4e4p07dzTlMTExIgAxICBAfPjwoab89ddfFx0cHMQHDx6UGcPw4cNFZ2dnrXqdO3cWAYjz5s3TlBUUFIitWrUSa9asKRYWFup/8/6VkpIiAhDfeustrfIJEyaIAMRdu3ZpyqKiokQXF5dSz/W48sa0e/duEYBYv359rfsVBEFs2LChGBYWJgqCoCm/d++e6OfnJ3br1k1TFhERITo6Omr9XE6dOiXa29vr/Wx8fX3FqKgozf60adNEAOKGDRv07qH4ukePHhUBiHFxcXp1oqKiRF9fX83+pk2bRADif//7X616r7zyiqhQKMRz585pygCIDg4OWmV//fWXCEBctGiR3rUe9+2334p2dnbivn37tMqXL18uAhD/+OMPrevY2dmJJ0+e1Kpb/Pvz3HPPiUVFRZry69eviw4ODmL37t1FtVqtKV+8eLEIQFy1apWmrPjnvHz58jLjJTI1dg2QliVLliAhIUFva9mypVa9DRs2QBAE9O/fH9nZ2ZrNy8sLDRs2xO7duzV1nZycNF/n5+cjOzsbwcHBEEURycnJ5Y6tX79+cHd31+x36NABAPDGG2+gUqVKWuWFhYXIzMwsMYa7d+8iOzsbnTp1wr1795Camqp1nUqVKmH48OGafQcHBwwfPhzXr1/HsWPHSo1v69atAIBx48ZplY8fPx4A8Ouvv5b7XnUZElNUVJTW/aakpODs2bP4z3/+g5s3b2p+Vvn5+XjhhRewd+9eCIIAtVqNHTt2ICIiAnXr1tUc36RJE4SFhT0xxp9++gkBAQF48cUX9V7TnXpYHlu3boW9vT1Gjx6tVT5+/HiIooht27ZplYeGhsLf31+z37JlS6hUKvzzzz9lXufHH39EkyZN0LhxY633cteuXQFA670MAJ07d0bTpk1LPNfQoUNhb2+v2f/9999RWFiIMWPGaA2sHDp0KFQqld57QqlUYtCgQWXGS2Rq7BogLe3bt0fbtm31yqtWrarVZXD27FmIooiGDRuWeJ7HmzvT09Mxbdo0/Pzzz7h9+7ZWvZycnHLH9vg/JwCapMDHx6fE8sevdfLkSbz//vvYtWuXps+8tBi8vb3h4uKiVfbMM88AeDRe4dlnny0xvkuXLsHOzg4NGjTQKvfy8kKVKlVw6dKlMu+vLIbE5Ofnp1Xv7NmzAB4lCKXJyclBQUEB7t+/X+LPtFGjRppEpzTnz5/Hyy+/XPaNGODSpUvw9vaGm5ubVnmTJk00rz9O9/0BPHrf6r7ndJ09exanT5+Gh4dHia9fv35da1/3+1vWa8UxNmrUSKvcwcEB9evX17uH2rVr2+wsErJdTAToqQiCAIVCgW3btml9Airm6uoKAFCr1ejWrRtu3bqFyZMno3HjxnBxcUFmZiYGDhxo0Ij2kq5TVrn474CyO3fuoHPnzlCpVPjwww/h7+8PR0dH/Pnnn5g8ebLJR9U/zadfU3q8NQCA5v7mzJlT6sJFrq6uegPjbM2T3gelEQQBLVq0wPz580t8XTfR1P3+lve18jD2eKKnwUSAnoq/vz9EUYSfn5/mk2lJjh8/jjNnzuDrr79GZGSkpjwhIUGvrrn+gSYmJuLmzZvYsGEDnn/+eU35hQsXSqx/5coV5Ofna30CP3PmDACUufKdr68vBEHA2bNnNZ9aAeDatWu4c+cOfH19n/oenjYmAJrmcpVKhdDQ0FLreXh4wMnJSdOC8Li0tLQnxujv748TJ06UWceQn7Gvry9+//133L17V6tVoLgrx5jv5+P8/f3x119/4YUXXjD5e7A4xrS0NNSvX19TXlhYiAsXLpT58yCyFI4RoKfy0ksvwd7eHjNnztT7xCWKIm7evAngf5/SHq8jiiI+//xzvXMW/5PTnVZlrJJiKCwsxNKlS0usX1RUpDVlrrCwECtWrICHhwcCAwNLvU7Pnj0BAJ999plWefEnzV69ej1V/MbEBACBgYHw9/fH3LlzkZeXp/f6jRs3ADz6PoWFhWHTpk1IT0/XvH769Gns2LHjiTG+/PLL+OuvvzSzIx5X/L035Gfcs2dPqNVqLF68WKt8wYIFUCgUCA8Pf+I5yqN///7IzMzEF198offa/fv3jVoPIDQ0FA4ODli4cKHW+++rr75CTk6OUe8JIlNhiwA9FX9/f/z3v/9FTEwMLl68iIiICLi5ueHChQvYuHEjhg0bhgkTJqBx48bw9/fHhAkTkJmZCZVKhZ9++qnEftvif2ijR49GWFgY7O3t8dprrxkda3BwMKpWrYqoqCiMHj0aCoUC3377balNxt7e3vjkk09w8eJFPPPMM1i7di1SUlKwcuXKMhfQCQgIQFRUFFauXKnpjjhy5Ai+/vprREREoEuXLk99D08bEwDY2dnhyy+/RHh4OJo1a4ZBgwahdu3ayMzMxO7du6FSqbBlyxYAwMyZM7F9+3Z06tQJI0eORFFRERYtWoRmzZrh77//LvM6EydOxPr169GvXz8MHjwYgYGBuHXrFn7++WcsX74cAQEB8Pf3R5UqVbB8+XK4ubnBxcUFHTp0KLHfvXfv3ujSpQvee+89XLx4EQEBAfjtt9+wefNmjBkzRmtgoDHefPNNrFu3Dm+//TZ2796Njh07Qq1WIzU1FevWrcOOHTtKHDdTHh4eHoiJicHMmTPRo0cP9OnTB2lpaVi6dCnatWuHN954wyT3QGQUKaYqkPUpnv509OjREl/v3Lmz1vTBYj/99JP43HPPiS4uLqKLi4vYuHFjMTo6WkxLS9PUOXXqlBgaGiq6urqKNWrUEIcOHaqZ2vX4NLKioiLxnXfeET08PESFQqGZrlY8fXDOnDla1y6eLvfjjz8+8V7++OMP8dlnnxWdnJxEb29vcdKkSeKOHTtEAOLu3bv17jMpKUkMCgoSHR0dRV9fX3Hx4sXl+j4+fPhQnDlzpujn5ydWrlxZ9PHxEWNiYrSmKIqi4dMHyxNTad+PYsnJyeJLL70kVq9eXVQqlaKvr6/Yv39/cefOnVr19uzZIwYGBooODg5i/fr1xeXLl4vTp09/4vRBURTFmzdviqNGjRJr164tOjg4iHXq1BGjoqLE7OxsTZ3NmzeLTZs2FStVqqT1HtCdPiiKonj37l1x7Nixore3t1i5cmWxYcOG4pw5c7SmQYrio2l90dHRevdcUowlKSwsFD/55BOxWbNmolKpFKtWrSoGBgaKM2fOFHNycp54nSf9/ixevFhs3LixWLlyZdHT01McMWKEePv2ba06pf2OEZmbQhSfMJKGSEZCQkKQnZ39xL5uS7LGmIio4uAYASIiIhljIkBERCRjTASIiIhkjGMEiIiIZIwtAkRERDLGRICIiEjGZLWgkCAIuHLlCtzc3CRfD56IiAwjiiLu3r0Lb29vrac5mtqDBw9QWFhoknM5ODjA0dHRJOcyF1klAleuXNF7gAgREdmWjIwM1KlTxyznfvDgAfx8XZF1XW2S83l5eeHChQtWnQzIKhEofnBJ1/UDUcnFeh71ee5aDalD0PPwmrPUIehxyrK+niyh7NV9JfGgVpHUIehx8Xz69frNpZlHltQh6Amuck7qEPR0draemPLyBHTpcEPv0dSmVFhYiKzralw6Vg8qN+P+5uTeFeAbeBGFhYVMBKxFcXdAJRcHVLaiRMDO2freIHZO1heTvdL6EgGFFSYCdk7WlwjYO1tfTNb0N6CYk6v1/Ul2dbHC3zsLdO26uing6mbcdQTYRhe09b3riIiIJKYWBaiNnFyvFgXTBGNm1pfqlWLZsmVo2bIlVCoVVCoVgoKCsG3bNqnDIiKiCkiAaJLNFthMIlCnTh18/PHHOHbsGJKSktC1a1f07dsXJ0+elDo0IiIim2UzXQO9e/fW2p89ezaWLVuGQ4cOoVmzZhJFRUREFZEAAcY27Bt/BsuwmUTgcWq1Gj/++CPy8/MRFBRUar2CggIUFBRo9nNzcy0RHhER2Ti1KEJt5Ar8xh5vKTbTNQAAx48fh6urK5RKJd5++21s3LgRTZs2LbV+bGws3N3dNRvXECAiItJmU4lAo0aNkJKSgsOHD2PEiBGIiorCqVOnSq0fExODnJwczZaRkWHBaImIyFbJabCgTXUNODg4oEGDBgCAwMBAHD16FJ9//jlWrFhRYn2lUgmlUmnJEImIqAIQIEJt5D9yW0kEbKpFQJcgCFpjAIiIiMgwNtMiEBMTg/DwcNStWxd3797F6tWrkZiYiB07dkgdGhERVTCmaNq3lRYBm0kErl+/jsjISFy9ehXu7u5o2bIlduzYgW7dukkdGhERVTBymjVgM4nAV199JXUIREREFY7NJAJERESWIvy7GXsOW8BEgIiISIfaBLMGjD3eUpgIEBER6VCLMMHTB00Ti7nZ9PRBIiIiMg5bBIiIiHRwjAAREZGMCVBADYXR57AF7BogIiKSMbYIEBER6RDER5ux57AFTASIiIh0qE3QNWDs8ZbCrgEiIiIZY4sAERGRDjm1CDARICIi0iGICgiikbMGjDzeUtg1QEREJGNMBIiIiHQUdw0Yu5XXsmXL0LJlS6hUKqhUKgQFBWHbtm1lHvPjjz+icePGcHR0RIsWLbB169anulcmAkRERDrUsDPJVl516tTBxx9/jGPHjiEpKQldu3ZF3759cfLkyRLrHzhwAK+//jqGDBmC5ORkREREICIiAidOnDD4XpkIEBER6RD/HSNgzCYaMEagd+/e6NmzJxo2bIhnnnkGs2fPhqurKw4dOlRi/c8//xw9evTAxIkT0aRJE8yaNQtt2rTB4sWLDb5XJgJERERmlJubq7UVFBSUWV+tVmPNmjXIz89HUFBQiXUOHjyI0NBQrbKwsDAcPHjQ4PiYCBAREekw5RgBHx8fuLu7a7bY2NgSr3n8+HG4urpCqVTi7bffxsaNG9G0adMS62ZlZcHT01OrzNPTE1lZWQbfK6cPEhER6VCLdlCLxn1WVv+7xHBGRgZUKpWmXKlUlli/UaNGSElJQU5ODtavX4+oqCjs2bOn1GTAVJgIEBERmVHxTIAncXBwQIMGDQAAgYGBOHr0KD7//HOsWLFCr66XlxeuXbumVXbt2jV4eXkZHB+7BoiIiHQIUECAnZGbkQsSCUKp4wmCgoKwc+dOrbKEhIRSxxSUhS0CREREOiy9xHBMTAzCw8NRt25d3L17F6tXr0ZiYiJ27NgBAIiMjETt2rU14wveffdddO7cGfPmzUOvXr2wZs0aJCUlYeXKlQbHKctE4Nz16rB3dpQ6DI2HWc5Sh6DH+ar1NRa5XLHCZ3pa4QqiCrX1/VrnP3STOgQ9yUX2Uoeg516Rg9Qh6LkrWM/fygd5RQCuPbGeLbp+/ToiIyNx9epVuLu7o2XLltixYwe6desGAEhPT4ed3f/+LgcHB2P16tV4//33MXXqVDRs2BCbNm1C8+bNDb629f3FICIikphpBguW/8PLV199VebriYmJemX9+vVDv379DA1LDxMBIiIiHY/GCBjZx2+NTYYlsL72XyIiIrIYtggQERHpEAx8VkDJ57DCcU0lYCJARESkw9JjBKTERICIiEhH8VoAxp3DNhIBjhEgIiKSMbYIEBER6VCLCqgNeIxwaeewBUwEiIiIdKhNMFhQza4BIiIisnZsESAiItIhiHYQjJw1IHDWABERkW1i1wARERHJAlsEiIiIdAgwftS/YJpQzI6JABERkQ7TLChkG43uthElERERmQVbBIiIiHSY5lkDtvFZm4kAERGRDgEKCDB2jABXFiQiIrJJcmoRsI0oiYiIyCzYIkBERKTDNAsK2cZnbSYCREREOgRRAcHYdQRs5OmDtpGuEBERkVmwRYCIiEiHYIKuAVtZUIiJABERkQ7TPH3QNhIB24gSQGxsLNq1awc3NzfUrFkTERERSEtLkzosIiIim2YzicCePXsQHR2NQ4cOISEhAQ8fPkT37t2Rn58vdWhERFTBqKEwyWYLbKZrYPv27Vr78fHxqFmzJo4dO4bnn39eoqiIiKgiklPXgM0kArpycnIAANWqVSu1TkFBAQoKCjT7ubm5Zo+LiIjIlthGuqJDEASMGTMGHTt2RPPmzUutFxsbC3d3d83m4+NjwSiJiMhWqWGK7gHbYJOJQHR0NE6cOIE1a9aUWS8mJgY5OTmaLSMjw0IREhGRLSvuGjB2swU21zUwatQo/PLLL9i7dy/q1KlTZl2lUgmlUmmhyIiIqKKQ00OHbCYREEUR77zzDjZu3IjExET4+flJHRIREZHNs5lEIDo6GqtXr8bmzZvh5uaGrKwsAIC7uzucnJwkjo6IiCoSEQoIRk7/Ezl90LSWLVsGAAgJCdEqj4uLw8CBAy0fEBERVVjsGrBCoihKHQIREVGFYzOJgCkVZblAcHSUOgwNlyvWlzW6ZApSh6DHLb3gyZUICsH6Bsjaqe2lDkHPPbWL1CHoOaX2lDoEPUVW9Kn2YX4hgJ0WuZacHkMsy0SAiIioLGoTPH3Q2OMtxTaiJCIiIrNgiwAREZEOdg0QERHJmAA7CEY2mht7vKXYRpRERERkFmwRICIi0qEWFVAb2bRv7PGWwkSAiIhIB8cIEBERyZhogqcHila0BkNZbCNKIiIiMgu2CBAREelQQwG1kQ8NMvZ4S2EiQEREpEMQje/jF2zkETnsGiAiIpIxtggQERHpEEwwWNDY4y2FiQAREZEOAQoIRvbxG3u8pdhGukJERFSBxcbGol27dnBzc0PNmjURERGBtLS0Mo+Jj4+HQqHQ2hwdHQ2+NhMBIiIiHcUrCxq7ldeePXsQHR2NQ4cOISEhAQ8fPkT37t2Rn59f5nEqlQpXr17VbJcuXTL4Xtk1QEREpMPSYwS2b9+utR8fH4+aNWvi2LFjeP7550s9TqFQwMvL66ljBNgiQEREZFa5ublaW0FBwROPycnJAQBUq1atzHp5eXnw9fWFj48P+vbti5MnTxocHxMBIiIiHQIUmucNPPX272BBHx8fuLu7a7bY2Niyry0IGDNmDDp27IjmzZuXWq9Ro0ZYtWoVNm/ejO+++w6CICA4OBiXL1826F7ZNUBERKRDNMGsAfHf4zMyMqBSqTTlSqWyzOOio6Nx4sQJ7N+/v8x6QUFBCAoK0uwHBwejSZMmWLFiBWbNmlXuOJkIEBER6TDl0wdVKpVWIlCWUaNG4ZdffsHevXtRp04dg65XuXJltG7dGufOnTPoOHYNEBERSUwURYwaNQobN27Erl274OfnZ/A51Go1jh8/jlq1ahl0HFsEiIiIdFh61kB0dDRWr16NzZs3w83NDVlZWQAAd3d3ODk5AQAiIyNRu3ZtzRiDDz/8EM8++ywaNGiAO3fuYM6cObh06RLeeustg+JkIkBERKTDlF0D5bFs2TIAQEhIiFZ5XFwcBg4cCABIT0+Hnd3/kovbt29j6NChyMrKQtWqVREYGIgDBw6gadOmBsXJRICIiEhiovjkRxUmJiZq7S9YsAALFiww+tpMBIiIiHTI6VkDTASIiIh0WLprQEqcNUBERCRjbBEgIiLSIacWASYCREREOuSUCLBrgIiISMbYIkBERKRDTi0CTASIiIh0iDB++t+TVwawDkwEiIiIdMipRYBjBIiIiGSMLQJEREQ65NQiIMtEwDHLDvZK62kMcbkiSB2CHtfMQqlD0OOQni11CDbBDTWkDkGPQlBKHYIeUWE9fwOK3bNzljoEPeftref9pL73wGLXklMiYH2/CURERGQxsmwRICIiKoucWgSYCBAREekQRQVEI/+RG3u8pbBrgIiISMbYIkBERKRDgMLoBYWMPd5SmAgQERHpkNMYAXYNEBERyRhbBIiIiHTIabAgEwEiIiIdcuoaYCJARESkQ04tAjY1RmDv3r3o3bs3vL29oVAosGnTJqlDIiIismlPlQg8fPgQGRkZSEtLw61bt0wdU6ny8/MREBCAJUuWWOyaREQkP+K/XQPGbLbSIlDuroG7d+/iu+++w5o1a3DkyBEUFhZCFEUoFArUqVMH3bt3x7Bhw9CuXTuzBRseHo7w8HCznZ+IiAgARACiaPw5bEG5WgTmz5+PevXqIS4uDqGhodi0aRNSUlJw5swZHDx4ENOnT0dRURG6d++OHj164OzZs+aOu1wKCgqQm5urtREREdH/lKtF4OjRo9i7dy+aNWtW4uvt27fH4MGDsXz5csTFxWHfvn1o2LChSQN9GrGxsZg5c6bUYRARkY0RoICCKwv+zw8//FCukymVSrz99ttGBWRKMTExGDdunGY/NzcXPj4+EkZERES2QE6zBir09EGlUgmlUil1GERERFarXInASy+9VO4Tbtiw4amDISIisgaCqICCCwr9j7u7u+ZrURSxceNGuLu7o23btgCAY8eO4c6dOwYlDE8jLy8P586d0+xfuHABKSkpqFatGurWrWvWaxMRkXyIoglmDdjItIFyJQJxcXGarydPnoz+/ftj+fLlsLe3BwCo1WqMHDkSKpXKPFH+KykpCV26dNHsF/f/R0VFIT4+3qzXJiIiqogMHiOwatUq7N+/X5MEAIC9vT3GjRuH4OBgzJkzx6QBPi4kJASiraRYRERks+Q0WNDglQWLioqQmpqqV56amgpBEEwSFBERkZSKEwFjN1tgcIvAoEGDMGTIEJw/fx7t27cHABw+fBgff/wxBg0aZPIAiYiILI2DBcswd+5ceHl5Yd68ebh69SoAoFatWpg4cSLGjx9v8gCJiIjIfAxOBOzs7DBp0iRMmjRJs2SvuQcJEhERWRJnDZQTEwAiIqqIHiUCxg4WNFEwZvZUicD69euxbt06pKeno7CwUOu1P//80ySBERERkfkZPGtg4cKFGDRoEDw9PZGcnIz27dujevXq+Oeff/iIYCIiqhDkNGvA4ERg6dKlWLlyJRYtWgQHBwdMmjQJCQkJGD16NHJycswRIxERkUWJJtpsgcGJQHp6OoKDgwEATk5OuHv3LgDgzTffLPdTComIiMg6GJwIeHl54datWwCAunXr4tChQwAerfvPVf+IiKgiYNdAGbp27Yqff/4ZwKPFhcaOHYtu3brh1VdfxYsvvmjyAImIiCxORn0DBs8aWLlypWYp4ejoaFSvXh0HDhxAnz59MHz4cJMHSEREZHGm+ERvIy0CBiUCRUVF+OijjzB48GDUqVMHAPDaa6/htddeM0twREREZF4GdQ1UqlQJn376KYqKiswVDxERkeSKVxY0drMFBo8ReOGFF7Bnzx5zxEJERGQV5DRY0OAxAuHh4ZgyZQqOHz+OwMBAuLi4aL3ep08fkwVnLk7ZIuwdrCdVc75ufS0sDlesb02IoowrUoegT1BLHYEeB3t7qUPQ4+xQXeoQ9BQpHaQOQY9QyeDPZmb3wN5Z6hA0hPvW9/2pCAxOBEaOHAkAmD9/vt5rCoUCarX1/WEkIiIyiKgwfrCfjbQIGJxeCYJQ6sYkgIiIKgJLjxGIjY1Fu3bt4Obmhpo1ayIiIgJpaWlPPO7HH39E48aN4ejoiBYtWmDr1q0G3yvbWYiIiCS2Z88eREdH49ChQ0hISMDDhw/RvXt35Ofnl3rMgQMH8Prrr2PIkCFITk5GREQEIiIicOLECYOuXa5EYM2aNeU+YUZGBv744w+DgiAiIrIqFl5QaPv27Rg4cCCaNWuGgIAAxMfHIz09HceOHSv1mM8//xw9evTAxIkT0aRJE8yaNQtt2rTB4sWLDbrVciUCy5YtQ5MmTfDpp5/i9OnTeq/n5ORg69at+M9//oM2bdrg5s2bBgVBRERkTUw5ayA3N1drKygoeOL1ix/iV61atVLrHDx4EKGhoVplYWFhOHjwoEH3Wq5EYM+ePfjkk0+QkJCA5s2bQ6VSoWHDhmjRogXq1KmD6tWrY/Dgwahbty5OnDhhEzMHiIiILMHHxwfu7u6aLTY2tsz6giBgzJgx6NixI5o3b15qvaysLHh6emqVeXp6Iisry6D4yj1roE+fPujTpw+ys7Oxf/9+XLp0Cffv30eNGjXQunVrtG7dGnZ2HHJAREQVhIlmmWdkZEClUmn2lUplmfWjo6Nx4sQJ7N+/3zQBPIHB0wdr1KiBiIgIM4RCRERkHUyxIFDx8SqVSisRKMuoUaPwyy+/YO/evZql/Evj5eWFa9euaZVdu3YNXl5eBsXJj/BERES6LDxYUBRFjBo1Chs3bsSuXbvg5+f3xGOCgoKwc+dOrbKEhAQEBQWV/8J4ihYBIiIiMq3o6GisXr0amzdvhpubm6af393dHU5OTgCAyMhI1K5dWzPG4N1330Xnzp0xb9489OrVC2vWrEFSUhJWrlxp0LXZIkBERKRHYaKtfJYtW4acnByEhISgVq1amm3t2rWaOunp6bh69apmPzg4GKtXr8bKlSsREBCA9evXY9OmTWUOMCwJWwSIiIh0Gdi0X+o5ylu1HMsQJiYm6pX169cP/fr1MyAofUa3CKjVaqSkpOD27dvGnoqIiIgszOBEYMyYMfjqq68APEoCOnfujDZt2sDHx6fEbIWIiMjmWHiwoJQMTgTWr1+PgIAAAMCWLVtw4cIFpKamYuzYsXjvvfdMHiAREZHFFT990NjNBhicCGRnZ2vmKG7duhX9+vXDM888g8GDB+P48eMmD5CIiIjMx+BEwNPTE6dOnYJarcb27dvRrVs3AMC9e/dgb29v8gCJiIgszdKPIZaSwbMGBg0ahP79+6NWrVpQKBSaBx4cPnwYjRs3NnmAREREFmfhWQNSMjgRmDFjBpo3b46MjAz069dPs2ayvb09pkyZYvIAiYiIyHyeah2BV155BQDw4MEDTVlUVJRpIiIiIpKaKQb7VdTBgmq1GrNmzULt2rXh6uqKf/75BwDwwQcfaKYVEhER2TKFaJrNFhicCMyePRvx8fH49NNP4eDgoClv3rw5vvzyS5MGR0REJAmuI1C6b775BitXrsSAAQO0ZgkEBAQgNTXVpMERERGReRk8RiAzMxMNGjTQKxcEAQ8fPjRJUERERJLiGIHSNW3aFPv27dMrX79+PVq3bm2SoIiIiCQlo64Bg1sEpk2bhqioKGRmZkIQBGzYsAFpaWn45ptv8Msvv5gjRiIiIjITg1sE+vbtiy1btuD333+Hi4sLpk2bhtOnT2PLli2aVQaJiIhsGlsEytapUyckJCSYOhYiIiLrIKOVBQ1uESAiIqKKo1wtAlWrVoVCUb7Rj7du3TIqICIiIsnJaNZAuRKBzz77zMxhEBERWQ9TrAxoKysLlisR4HMEiIiIKiaDxwjk5uaWuN29exeFhYXmiFHLkiVLUK9ePTg6OqJDhw44cuSI2a9JREQyI6NZAwYnAlWqVEHVqlX1tipVqsDJyQm+vr6YPn06BEEwebBr167FuHHjMH36dPz5558ICAhAWFgYrl+/bvJrERERyYHBiUB8fDy8vb0xdepUbNq0CZs2bcLUqVNRu3ZtLFu2DMOGDcPChQvx8ccfmzzY+fPnY+jQoRg0aBCaNm2K5cuXw9nZGatWrTL5tYiISL4UMMHTB6W+iXIyeB2Br7/+GvPmzUP//v01Zb1790aLFi2wYsUK7Ny5E3Xr1sXs2bMxdepUkwVaWFiIY8eOISYmRlNmZ2eH0NBQHDx4sMRjCgoKUFBQoNnPzc01WTxEREQVgcGJwIEDB7B8+XK98tatW2v+IT/33HNIT083PrrHZGdnQ61Ww9PTU6vc09Oz1KcexsbGYubMmXrlBe4K2CutJ1ernP9U6zqZVaU8V6lD0FM53/PJlSxMLCqSOgQ9RTXcpA5BT0FV63uPF6qs529AsYduVtiprLKih8lVtmAsMpo+aHDXgI+PD7766iu98q+++go+Pj4AgJs3b6Jq1arGR2ekmJgY5OTkaLaMjAypQyIiIlsgo8GCBqfpc+fORb9+/bBt2za0a9cOAJCUlITU1FSsX78eAHD06FG8+uqrJg20Ro0asLe3x7Vr17TKr127Bi8vrxKPUSqVUCqVJo2DiIioIjG4RaBPnz5ITU1FeHg4bt26hVu3biE8PBypqan4v//7PwDAiBEjMH/+fJMG6uDggMDAQOzcuVNTJggCdu7ciaCgIJNei4iIZI4tAmXz8/Mzy6yAJxk3bhyioqLQtm1btG/fHp999hny8/MxaNAgi8dCREQVF1cWfII7d+7gyJEjuH79ut56AZGRkSYJrCSvvvoqbty4gWnTpiErKwutWrXC9u3b9QYQEhERUfkYnAhs2bIFAwYMQF5eHlQqldbDiBQKhVkTAQAYNWoURo0aZdZrEBGRzPExxKUbP348Bg8ejLy8PNy5cwe3b9/WbHzyIBERVQgyGiNgcCKQmZmJ0aNHw9nZ2RzxEBERkQUZnAiEhYUhKSnJHLEQERFZBaOXFzbBYENLMXiMQK9evTBx4kScOnUKLVq0QOXKlbVe79Onj8mCIyIikoSMVhY0OBEYOnQoAODDDz/Ue02hUECtVhsfFRERkZRkNFjQ4ETAHI8XJiIiImlY35NAiIiIJMYFhZ4gPz8fe/bsQXp6OgoLC7VeGz16tEkCIyIikgy7BkqXnJyMnj174t69e8jPz0e1atWQnZ0NZ2dn1KxZk4kAERGRDTF4+uDYsWPRu3dv3L59G05OTjh06BAuXbqEwMBAzJ071xwxEhERWZYppg7aSIuAwYlASkoKxo8fDzs7O9jb26OgoAA+Pj749NNPMXXqVHPESEREZFlcWbB0lStXhp3do8Nq1qyJ9PR0AIC7uzsyMjJMGx0RERGZlcFjBFq3bo2jR4+iYcOG6Ny5M6ZNm4bs7Gx8++23aN68uTliJCIisiwZDRY0uEXgo48+Qq1atQAAs2fPRtWqVTFixAjcuHEDK1euNHmARERElsYlhsvQtm1bzdc1a9bE9u3bTRoQERERWY7BLQJERERUcXBlQSIiIl0yGiPARICIiEiHnJYYZtcAERGRjDERICIiKomFFxPau3cvevfuDW9vbygUCmzatKnM+omJiVAoFHpbVlaWQdc1KBG4f/8+9u/fj1OnTum99uDBA3zzzTcGXZyIiMgqSbCyYH5+PgICArBkyRKDjktLS8PVq1c1W82aNQ06vtxjBM6cOYPu3bsjPT0dCoUCzz33HNasWaNZUyAnJweDBg1CZGSkQQEQEREREB4ejvDwcIOPq1mzJqpUqfLU1y13i8DkyZPRvHlzXL9+HWlpaXBzc0PHjh01SwwTERFVFLa0oFCrVq1Qq1YtdOvWDX/88YfBx5e7ReDAgQP4/fffUaNGDdSoUQNbtmzByJEj0alTJ+zevRsuLi4GX5yIiMgqmXD6YG5urlaxUqmEUqk08uRArVq1sHz5crRt2xYFBQX48ssvERISgsOHD6NNmzblPk+5WwTu37+PSpX+lzcoFAosW7YMvXv3RufOnXHmzBnD7oCIiEgGfHx84O7urtliY2NNct5GjRph+PDhCAwMRHBwMFatWoXg4GAsWLDAoPOUu0WgcePGSEpKQpMmTbTKFy9eDADo06ePQRcmIiKyVqZcRyAjIwMqlUpTborWgNK0b98e+/fvN+iYcrcIvPjii/jhhx9KfG3x4sV4/fXXIYo2snoCERFRWUw4a0ClUmlt5kwEUlJSNIP4y6vciUBMTAy2bt1a6utLly6FIAgGXZyIiIgeycvLQ0pKClJSUgAAFy5cQEpKimZQfkxMjNbMvM8++wybN2/GuXPncOLECYwZMwa7du1CdHS0QdflEsNERES6JHjWQFJSErp06aLZHzduHAAgKioK8fHxuHr1qtZMvcLCQowfPx6ZmZlwdnZGy5Yt8fvvv2udozyYCBAREemQ4lkDISEhZXaxx8fHa+1PmjQJkyZNeorItMkyEbjvLcDO0Xq6MUR761vpWbR3kjoEPa72nlKHoEdRZD3vo2J5vtb3s8urbX3v8fue1jemSaj1QOoQ9PjVuil1CBpF+QXIsNTFZPT0Qev77SQiIiKLMTgR0F0Y4XHnzp0zKhgiIiKrIMGzBqRicCLQq1cvFBQU6JWnpaUhJCTEFDERERFJypaWGDaWwYmAq6srXnzxRRQVFWnKTp8+jZCQELz88ssmDY6IiIjMy+BEYMOGDcjJycGAAQMgiiJOnDiBkJAQvP766/j888/NESMREZFlsWugdE5OTvj111+RlpaG/v3744UXXkBkZCTmz59vjviIiIgsTk5dA+WaPqg7QNDOzg5r165Ft27d8PLLL+ODDz7Q1Hl8PWUiIiKybuVKBKpUqQKFQqFXLooili9fjhUrVkAURSgUCqjVapMHSUREZFEyWkegXInA7t27zR0HERGR9WAioK1z587mjoOIiIgk8FRLDN+5cwdHjhzB9evX9Z44+PiTkYiIiGyR4t/N2HPYAoMTgS1btmDAgAHIy8uDSqXSGjugUCiYCBARke2TUdeAwdMHx48fj8GDByMvLw937tzB7du3NdutW7fMESMREZFFyWn6oMGJQGZmJkaPHg1nZ2dzxENEREQWZHAiEBYWhqSkJHPEQkREZB1ktLKgwWMEevXqhYkTJ+LUqVNo0aIFKleurPV6nz59TBYcERGRZGzkH7mxDE4Ehg4dCgD48MMP9V4z54JCs2fPxq+//oqUlBQ4ODjgzp07ZrkOERGRnBjcNSAIQqmbOVcVLCwsRL9+/TBixAizXYOIiAiQ12DBp1pHQAozZ84EAMTHx0sbCBERVXwymj5YrkRg4cKFGDZsGBwdHbFw4cIy644ePdokgREREZH5lSsRWLBgAQYMGABHR0csWLCg1HoKhcKqEoGCggIUFBRo9nWfokhERFQSUzTtV6iugQsXLpT4tbGmTJmCTz75pMw6p0+fRuPGjZ/q/LGxsZouBSIionJj14BljB8/HgMHDiyzTv369Z/6/DExMRg3bpxmPzc3Fz4+Pk99PiIiooqmXInA4/9Mn2T+/Pnlruvh4QEPD49y1zeUUqmEUqk02/mJiKhiYteAjuTk5HKd7PEHEJlaeno6bt26hfT0dKjVaqSkpAAAGjRoAFdXV7Ndl4iIZIhdA9p2795t7jieaNq0afj66681+61btwbwKLaQkBCJoiIiogpJRomAwQsKSSU+Ph6iKOptTAKIiIiens0sKERERGQpHCNAREQkZ+waICIiIjlgiwAREZEOhShCIRr3kd7Y4y2FiQAREZEudg0QERGRHLBFgIiISAdnDRAREckZuwaIiIhIDmTZIiB6FEB0Nt9zEQx1X3CUOgQ9CsEKc0TR+h4gZY1Nf3ne1vezu+dlhd8o7wdSR6CnnudNqUPQ06H6RalD0ChQPsR+C12LXQNERERyJqOuASYCREREOuTUImB9bYhERERkMWwRICIi0sWuASIiInmzlaZ9Y7FrgIiISMbYIkBERKRLFB9txp7DBjARICIi0sFZA0RERCQLbBEgIiLSxVkDRERE8qUQHm3GnsMWsGuAiIhIxpgIEBER6RJNtBlg79696N27N7y9vaFQKLBp06YnHpOYmIg2bdpAqVSiQYMGiI+PN+yiYCJARESkp3jWgLGbIfLz8xEQEIAlS5aUq/6FCxfQq1cvdOnSBSkpKRgzZgzeeust7Nixw6DrcowAERGRLgnWEQgPD0d4eHi56y9fvhx+fn6YN28eAKBJkybYv38/FixYgLCwsHKfhy0CRERENujgwYMIDQ3VKgsLC8PBgwcNOg9bBIiIiHSYckGh3NxcrXKlUgmlUmncyQFkZWXB09NTq8zT0xO5ubm4f/8+nJycynUetggQERHpMuFgQR8fH7i7u2u22NhYi97Kk7BFgIiIyIwyMjKgUqk0+6ZoDQAALy8vXLt2Tavs2rVrUKlU5W4NAJgIEBER6TFl14BKpdJKBEwlKCgIW7du1SpLSEhAUFCQQedh1wAREZGu4lkDxm4GyMvLQ0pKClJSUgA8mh6YkpKC9PR0AEBMTAwiIyM19d9++238888/mDRpElJTU7F06VKsW7cOY8eONei6TASIiIisQFJSElq3bo3WrVsDAMaNG4fWrVtj2rRpAICrV69qkgIA8PPzw6+//oqEhAQEBARg3rx5+PLLLw2aOgiwa4CIiEiPFI8hDgkJgVhGK0JJqwaGhIQgOTnZwMi0MREgIiLSJaOnD7JrgIiISMbYIkBERKRDiq4BqTARICIi0iWIjzZjz2EDmAgQERHp4hgBIiIikgO2CBAREelQwARjBEwSifkxESAiItL1FCsDlngOG8CuASIiIhljiwAREZEOTh8kIiKSM84aICIiIjlgiwAREZEOhShCYeRgP2OPtxRZJgK1auSgkssDqcPQyBSrSB2CnvuCo9Qh6FGora8BS6gsdQT67nsJUoegr5b1/L4V8/O8KXUIejpUvyh1CHpC3U5KHYJGvkKNzyx1MeHfzdhz2ADr+8tKREREFmMTicDFixcxZMgQ+Pn5wcnJCf7+/pg+fToKCwulDo2IiCqg4q4BYzdbYBNdA6mpqRAEAStWrECDBg1w4sQJDB06FPn5+Zg7d67U4RERUUUjo1kDNpEI9OjRAz169NDs169fH2lpaVi2bBkTASIiMj2uLGj9cnJyUK1aNanDICIismk20SKg69y5c1i0aNETWwMKCgpQUFCg2c/NzTV3aEREVAHIaWVBSVsEpkyZAoVCUeaWmpqqdUxmZiZ69OiBfv36YejQoWWePzY2Fu7u7prNx8fHnLdDREQVRXHXgLGbDZC0RWD8+PEYOHBgmXXq16+v+frKlSvo0qULgoODsXLlyieePyYmBuPGjdPs5+bmMhkgIiJ6jKSJgIeHBzw8PMpVNzMzE126dEFgYCDi4uJgZ/fkxgylUgmlUmlsmEREJDMK4dFm7DlsgU2MEcjMzERISAh8fX0xd+5c3LhxQ/Oal5eXhJEREVGFJKNZAzaRCCQkJODcuXM4d+4c6tSpo/WaaCPfaCIiImtkE9MHBw4cCFEUS9yIiIhMTjTRZgNsokWAiIjIkuT09EGbaBEgIiIi82CLABERkS4OFiQiIpIxEYCx0/9sIw9gIkBERKSLYwSIiIhIFtgiQEREpEuECcYImCQSs2MiQEREpEtGgwXZNUBERCRjbBEgIiLSJQBQmOAcNoCJABERkQ7OGiAiIiJZYIsAERGRLhkNFmQiQEREpEtGiQC7BoiIiGSMLQJERES6ZNQiwESAiIhIF6cPEhERyRenDxIREZEssEWAiIhIF8cIEBERyZggAgoj/5ELtpEIsGuAiIhIxtgiQEREpItdA0RERHJmgkQATASsVstqV+DgWlnqMDQK1fZSh6DnWqH1xfSgyHp+ZsXUSiv8Ra/1QOoI9PjWvCV1CHraVbskdQh6nndNlToEPSFO1jMZPrfICn/fKgCOESAiItJV3DVg7GagJUuWoF69enB0dESHDh1w5MiRUuvGx8dDoVBobY6OjgZfk4kAERGRLkE0zWaAtWvXYty4cZg+fTr+/PNPBAQEICwsDNevXy/1GJVKhatXr2q2S5cMb+liIkBERGQF5s+fj6FDh2LQoEFo2rQpli9fDmdnZ6xatarUYxQKBby8vDSbp6enwddlIkBERKRLFEyzAcjNzdXaCgoK9C5XWFiIY8eOITQ0VFNmZ2eH0NBQHDx4sNQw8/Ly4OvrCx8fH/Tt2xcnT540+FaZCBAREeky4RgBHx8fuLu7a7bY2Fi9y2VnZ0OtVut9ovf09ERWVlaJITZq1AirVq3C5s2b8d1330EQBAQHB+Py5csG3aosZw0QERGVSRBh9PS/f8cIZGRkQKVSaYqVSqVx5/1XUFAQgoKCNPvBwcFo0qQJVqxYgVmzZpX7PEwEiIiIzEilUmklAiWpUaMG7O3tce3aNa3ya9euwcvLq1zXqVy5Mlq3bo1z584ZFB+7BoiIiHRZePqgg4MDAgMDsXPnTk2ZIAjYuXOn1qf+sqjVahw/fhy1atUy6FbZIkBERKRLhAmWGDas+rhx4xAVFYW2bduiffv2+Oyzz5Cfn49BgwYBACIjI1G7dm3NGIMPP/wQzz77LBo0aIA7d+5gzpw5uHTpEt566y2DrstEgIiIyAq8+uqruHHjBqZNm4asrCy0atUK27dv1wwgTE9Ph53d/xryb9++jaFDhyIrKwtVq1ZFYGAgDhw4gKZNmxp0XSYCREREuiR66NCoUaMwatSoEl9LTEzU2l+wYAEWLFjwNJFpYSJARESkSxAAGPmcBcF6ntNQFg4WJCIikjG2CBAREemSqGtACkwEiIiIdMkoEWDXABERkYyxRYCIiEiXCZcYtnZMBIiIiHSIogBRNG7Uv7HHWwoTASIiIl2iaPwneo4RICIiImvHFgEiIiJdognGCNhIiwATASIiIl2CACiM7OO3kTEC7BogIiKSMZtJBPr06YO6devC0dERtWrVwptvvokrV65IHRYREVVExQsKGbvZAJtJBLp06YJ169YhLS0NP/30E86fP49XXnlF6rCIiKgCEgXBJJstsJkxAmPHjtV87evriylTpiAiIgIPHz5E5cqVJYyMiIjIdtlMIvC4W7du4fvvv0dwcHCZSUBBQQEKCgo0+7m5uZYIj4iIbJ2MZg3YTNcAAEyePBkuLi6oXr060tPTsXnz5jLrx8bGwt3dXbP5+PhYKFIiIrJpgmiazQZImghMmTIFCoWizC01NVVTf+LEiUhOTsZvv/0Ge3t7REZGQiwj44qJiUFOTo5my8jIsMRtERER2QxJuwbGjx+PgQMHllmnfv36mq9r1KiBGjVq4JlnnkGTJk3g4+ODQ4cOISgoqMRjlUollEqlKUMmIiI5EEUAxq4jYBstApImAh4eHvDw8HiqY4V/R2M+PgaAiIjIFERBhKgw7h95WS3W1sQmBgsePnwYR48exXPPPYeqVavi/Pnz+OCDD+Dv719qawAREdFTEwUY3yJgG9MHbWKwoLOzMzZs2IAXXngBjRo1wpAhQ9CyZUvs2bOHTf9ERERGsIkWgRYtWmDXrl1Sh0FERDLBrgEiIiI5k1HXgKwSgeLsrDD/ocSRaFPnW9+AR+H+A6lD0CM8UEsdgh7BGjP+e9b3syuywvd4gdK6/g4AQD6s7z2eq7aef2a5eY9iscQn7SI8NHo9oSJY33usJArRVtouTODy5ctcVIiIyMZlZGSgTp06Zjn3gwcP4Ofnh6ysLJOcz8vLCxcuXICjo6NJzmcOskoEBEHAlStX4ObmBoVCofd6bm4ufHx8kJGRAZVKJUGElsN7rZjkcq9yuU+A9/o4URRx9+5deHt7w87OfGPdHzx4gMLCQpOcy8HBwaqTAEBmXQN2dnblyiJVKlWF/4UrxnutmORyr3K5T4D3Wszd3d3s13d0dLT6f96mZBPTB4mIiMg8mAgQERHJGBOBxyiVSkyfPl0WixTxXismudyrXO4T4L2S+clqsCARERFpY4sAERGRjDERICIikjEmAkRERDLGRICIiEjGmAiUok+fPqhbty4cHR1Rq1YtvPnmm7hy5YrUYZncxYsXMWTIEPj5+cHJyQn+/v6YPn26yVbVsjazZ89GcHAwnJ2dUaVKFanDMaklS5agXr16cHR0RIcOHXDkyBGpQzKLvXv3onfv3vD29oZCocCmTZukDsksYmNj0a5dO7i5uaFmzZqIiIhAWlqa1GGZxbJly9CyZUvNQkJBQUHYtm2b1GHJBhOBUnTp0gXr1q1DWloafvrpJ5w/fx6vvPKK1GGZXGpqKgRBwIoVK3Dy5EksWLAAy5cvx9SpU6UOzSwKCwvRr18/jBgxQupQTGrt2rUYN24cpk+fjj///BMBAQEICwvD9evXpQ7N5PLz8xEQEIAlS5ZIHYpZ7dmzB9HR0Th06BASEhLw8OFDdO/eHfn5+VKHZnJ16tTBxx9/jGPHjiEpKQldu3ZF3759cfLkSalDkweRymXz5s2iQqEQCwsLpQ7F7D799FPRz89P6jDMKi4uTnR3d5c6DJNp3769GB0drdlXq9Wit7e3GBsbK2FU5gdA3Lhxo9RhWMT169dFAOKePXukDsUiqlatKn755ZdShyELbBEoh1u3buH7779HcHAwKleuLHU4ZpeTk4Nq1apJHQaVU2FhIY4dO4bQ0FBNmZ2dHUJDQ3Hw4EEJIyNTysnJAYAK/7upVquxZs0a5OfnIygoSOpwZIGJQBkmT54MFxcXVK9eHenp6di8ebPUIZnduXPnsGjRIgwfPlzqUKicsrOzoVar4enpqVXu6elpskepkrQEQcCYMWPQsWNHNG/eXOpwzOL48eNwdXWFUqnE22+/jY0bN6Jp06ZShyULskoEpkyZAoVCUeaWmpqqqT9x4kQkJyfjt99+g729PSIjIyHayEKMht4rAGRmZqJHjx7o168fhg4dKlHkhnuaeyWyJdHR0Thx4gTWrFkjdShm06hRI6SkpODw4cMYMWIEoqKicOrUKanDkgVZLTF848YN3Lx5s8w69evXh4ODg1755cuX4ePjgwMHDthEc5Wh93rlyhWEhITg2WefRXx8vFmf9W1qT/NzjY+Px5gxY3Dnzh0zR2d+hYWFcHZ2xvr16xEREaEpj4qKwp07dyp0S5ZCocDGjRu17ruiGTVqFDZv3oy9e/fCz89P6nAsJjQ0FP7+/lixYoXUoVR4laQOwJI8PDzg4eHxVMcKggAAKCgoMGVIZmPIvWZmZqJLly4IDAxEXFycTSUBgHE/14rAwcEBgYGB2Llzp+YfoiAI2LlzJ0aNGiVtcPTURFHEO++8g40bNyIxMVFWSQDw6D1sK39vbZ2sEoHyOnz4MI4ePYrnnnsOVatWxfnz5/HBBx/A39/fJloDDJGZmYmQkBD4+vpi7ty5uHHjhuY1Ly8vCSMzj/T0dNy6dQvp6elQq9VISUkBADRo0ACurq7SBmeEcePGISoqCm3btkX79u3x2WefIT8/H4MGDZI6NJPLy8vDuXPnNPsXLlxASkoKqlWrhrp160oYmWlFR0dj9erV2Lx5M9zc3DTjPdzd3eHk5CRxdKYVExOD8PBw1K1bF3fv3sXq1auRmJiIHTt2SB2aPEg7acE6/f3332KXLl3EatWqiUqlUqxXr5749ttvi5cvX5Y6NJOLi4sTAZS4VURRUVEl3uvu3bulDs1oixYtEuvWrSs6ODiI7du3Fw8dOiR1SGaxe/fuEn+GUVFRUodmUqX9XsbFxUkdmskNHjxY9PX1FR0cHEQPDw/xhRdeEH/77Tepw5INWY0RICIiIm221RlMREREJsVEgIiISMaYCBAREckYEwEiIiIZYyJAREQkY0wEiIiIZIyJABERkYwxEaAKKSQkBGPGjNHs16tXD5999lm5j09MTIRCoagQzyIALHc/b775Jj766COznHvGjBlo1aqVZn/KlCl45513zHItIjlhIkCycPToUQwbNsys19i7dy969+4Nb29vKBQKbNq0yazXszZ//fUXtm7ditGjR1vkehMmTMDXX3+Nf/75xyLXI6qomAiQLHh4eMDZ2dms18jPz0dAQACWLFli1utYq0WLFqFfv35lPrOhsLDQZNerUaMGwsLCsGzZMpOdk0iOmAiQLOh2DSgUCnz55Zd48cUX4ezsjIYNG+Lnn38u9fh79+4hPDwcHTt2LLV5PTw8HP/973/x4osvljuu8+fPo2/fvvD09ISrqyvatWuH33//XS/2jz76CIMHD4abmxvq1q2LlStXatU5cOAAWrVqBUdHR7Rt2xabNm2CQqHQPFSpJPv370enTp3g5OQEHx8fjB49Gvn5+ZrXly5dioYNG8LR0RGenp545ZVXSj2XWq3G+vXr0bt3b73YZ82ahcjISKhUKk2rzOTJk/HMM8/A2dkZ9evXxwcffICHDx9qHfvxxx/D09MTbm5uGDJkCB48eKB33d69e2PNmjWlxkVET8ZEgGRr5syZ6N+/P/7++2/07NkTAwYMwK1bt/Tq3blzB926dYMgCEhISECVKlVMFkNeXh569uyJnTt3Ijk5GT169EDv3r2Rnp6uVW/evHlo27YtkpOTMXLkSIwYMQJpaWkAgNzcXPTu3RstWrTAn3/+iVmzZmHy5MllXvf8+fPo0aMHXn75Zfz9999Yu3Yt9u/fr3lscVJSEkaPHo0PP/wQaWlp2L59O55//vlSz/f3338jJycHbdu21Xtt7ty5CAgIQHJyMj744AMAgJubG+Lj43Hq1Cl8/vnn+OKLL7BgwQLNMevWrcOMGTPw0UcfISkpCbVq1cLSpUv1zt2+fXtcvnwZFy9eLPN+iagMUj/1iMgcOnfuLL777ruafV9fX3HBggWafQDi+++/r9nPy8sTAYjbtm0TRfF/T7g7ffq02LJlS/Hll18WCwoKyn19AOLGjRufKvZmzZqJixYt0or9jTfe0OwLgiDWrFlTXLZsmSiKorhs2TKxevXq4v379zV1vvjiCxGAmJycrHU/t2/fFkVRFIcMGSIOGzZM67r79u0T7ezsxPv374s//fSTqFKpxNzc3HLFvHHjRtHe3l4UBEGr3NfXV4yIiHji8XPmzBEDAwM1+0FBQeLIkSO16nTo0EEMCAjQKsvJyREBiImJieWKk4j0sUWAZKtly5aar11cXKBSqXD9+nWtOt26dUODBg2wdu1aODg4mDyGvLw8TJgwAU2aNEGVKlXg6uqK06dP67UIPB6rQqGAl5eXJta0tDS0bNkSjo6Omjrt27cv87p//fUX4uPj4erqqtnCwsIgCAIuXLiAbt26wdfXF/Xr18ebb76J77//Hvfu3Sv1fPfv34dSqYRCodB7raRWgrVr16Jjx47w8vKCq6sr3n//fa17Pn36NDp06KB1TFBQkN55nJycAKDM2IiobEwESLYqV66sta9QKCAIglZZr169sHfvXpw6dcosMUyYMAEbN27ERx99hH379iElJQUtWrTQG1RXnlgNkZeXh+HDhyMlJUWz/fXXXzh79iz8/f3h5uaGP//8Ez/88ANq1aqFadOmISAgoNTxETVq1MC9e/dKHAzo4uKitX/w4EEMGDAAPXv2xC+//ILk5GS89957TzWQsLgrx8PDw+BjieiRSlIHQGTNPv74Y7i6uuKFF15AYmIimjZtatLz//HHHxg4cKBmgGFeXp7B/d2NGjXCd999h4KCAiiVSgCPpkuWpU2bNjh16hQaNGhQap1KlSohNDQUoaGhmD59OqpUqYJdu3bhpZde0qtbPL//1KlTWnP9S3LgwAH4+vrivffe05RdunRJq06TJk1w+PBhREZGasoOHTqkd64TJ06gcuXKaNasWZnXJKLSsUWA6Anmzp2LAQMGoGvXrkhNTS21Xl5enubTNQBcuHABKSkpes38j2vYsCE2bNig+UT+n//8x+BP+sXHDBs2DKdPn8aOHTswd+5cACixqR54NGr/wIEDGDVqFFJSUnD27Fls3rxZM1jwl19+wcKFC5GSkoJLly7hm2++gSAIaNSoUYnn8/DwQJs2bbB///4nxtuwYUOkp6djzZo1OH/+PBYuXIiNGzdq1Xn33XexatUqxMXF4cyZM5g+fTpOnjypd659+/ZpZj4Q0dNhIkBUDgsWLED//v3RtWtXnDlzpsQ6SUlJaN26NVq3bg0AGDduHFq3bo1p06aVet758+ejatWqCA4ORu/evREWFoY2bdoYFJtKpcKWLVuQkpKCVq1a4b333tNc8/FxA49r2bIl9uzZgzNnzqBTp06aOL29vQEAVapUwYYNG9C1a1c0adIEy5cvxw8//FDmJ++33noL33///RPj7dOnD8aOHYtRo0ahVatWOHDggGY2QbFXX30VH3zwASZNmoTAwEBcunQJI0aM0DvXmjVrMHTo0Cdek4hKpxBFUZQ6CCIyre+//x6DBg1CTk6OxT4t379/H40aNcLatWtLHNhnatu2bcP48ePx999/o1Il9nISPS3+9hBVAN988w3q16+P2rVr46+//sLkyZPRv39/izaZOzk54ZtvvkF2drZFrpefn4+4uDgmAURGYosAUQXw6aefYunSpcjKykKtWrUQERGB2bNnm31ZZSKyfUwEiIiIZIyDBYmIiGSMiQAREZGMMREgIiKSMSYCREREMsZEgIiISMaYCBAREckYEwEiIiIZYyJAREQkY0wEiIiIZOz/AZ/ff3DX51kmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# If working on CodeSpaces, run this cell before running the next model to free up memory\n",
    "if not AUTOGRADING:\n",
    "    model_cnn_scripted = torch.jit.script(model_cnn)\n",
    "    model_cnn_scripted.save(str(statedicts_dir / \"task_1-3_model_cnn.pt\"))\n",
    "\n",
    "\n",
    "\n",
    "    _, test_dataset_cnn = load_test_dataset_dataloader(\n",
    "        datasets_dir / \"dataset_double_pendulum_test.npz\",\n",
    "        _rng=init_rng,\n",
    "        model_type=\"cnn\",\n",
    "    )\n",
    "\n",
    "    evaluate_model(\n",
    "        model_cnn,\n",
    "        test_dataset_cnn,\n",
    "        model=\"cnn\",\n",
    "        file=\"task_1-3_model_cnn_prediction_error.pdf\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4111128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel train_loader_cnn\n",
    "%xdel val_loader_cnn\n",
    "%xdel test_loader_cnn\n",
    "%xdel model_cnn_scripted\n",
    "\n",
    "%xdel test_dataset_cnn\n",
    "%xdel model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c25c09788fbb8230aa75a0ceaace2a6",
     "grade": false,
     "grade_id": "cell-a5bc36d52b583442",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 - Analyse and Compare Model performance \n",
    "Make a comparison of the different models (i.e. M Œ∏, M trig, M cnn) based on the average prediction accuracy\n",
    "on the test dataset and the number of trainable parameters. Which model would you prefer and why? (answer in the cell below)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63b207d5e7a1ae467cf7f674fc199c2e",
     "grade": true,
     "grade_id": "cell-e2d3ff8fab5701aa",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: Compared to other models -- $M_{\\theta}$ and $M_{trig}$, $M_{cnn}$ has better performance on the test set. Also, CNN model only has 17040 trainable parameters which is way less than other models (almost 400000 parameters). Though the convolution operation requires more time for CPU, the GPU enable the computer to perform the operation fast. Based on the above observation, CNN model is preferred.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c145f5b06628fb57436f5c063db3ddc",
     "grade": false,
     "grade_id": "cell-13a942a4eeaa6fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you change the activation of the last fully connected layer to ReLU, the prediction accuracy completely deteriorates. Why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f9c152abcbff44ee619c7c6a1bde535",
     "grade": true,
     "grade_id": "cell-d18c9ec4e98b87c4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: The model is predicting the $cos(\\theta)$ and $sin(\\theta)$. These two value all ranges within $[-1,1]$, however, the relu() set all negative value to 0 and remain all positive value. The prediction will certainly be affected because the negative value are very useful in predicting the actual $\\theta$ and should not be eliminated by relu().**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1b972003f280e0432a7c8abcc34fc86",
     "grade": false,
     "grade_id": "cell-6d6768e940504fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.4: Variance across runs (2.5p) \n",
    "In the previous tasks, the prediction accuracy varied across different runs even though the underlying code and dataset remained unchanged.\n",
    "\n",
    "Use the code cell below to set the seed for PyTorch. Train the model for a seed of 0 and then for seed of 1, recording the average prediction accuracy and standard deviation for both.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: only run this cell once as it resets your results for all seeds\n",
    "# initialize dictionary to keep track of prediction error across seeds\n",
    "pred_error_sds = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)  # set seed to either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_loader_theta, val_loader_theta = load_training_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_train.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )\n",
    "    test_loader_theta, _ = load_test_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_test.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5786b377792f4673531702e631881ab3",
     "grade": false,
     "grade_id": "cell-1910ebea89f95d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Copy the architecture of $M_{\\theta}$ to create a new model below. Don't forget to comment on the code to set the seed again when working on the other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a656a453e8d3ce79bd55eec8f0d8a90",
     "grade": true,
     "grade_id": "cell-cc04b732f5935e1b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" TASK 1.4: CREATE MODEL HERE \"\"\"\n",
    "\n",
    "\n",
    "class NeuralNetworkThetaSeed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        input_size = 32*32*3\n",
    "        hiden_size = 128\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(input_size,hiden_size)\n",
    "        self.act_fn = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hiden_size, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n",
    "\"\"\"TASK1.4: END\"\"\"\n",
    "model_theta_seed = NeuralNetworkThetaSeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8495339b332c4c04d23b078132e7e18",
     "grade": false,
     "grade_id": "cell-ab56a3b7cc55c6c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Set up a training loop as done for the task 1.3 and run this 10 times while having the seed value as 0 and then run it again for a seed of 1. Use the same datasets as in task 1.3. **(0.5p)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = torch.optim.SGD(model_theta_seed.parameters(), lr=1e-3)\n",
    "# We choose the mean square loss as it is a regression problem\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 30\n",
    "\n",
    "# define the path to save the model to\n",
    "model_theta_seed_path = str(statedicts_dir / f\"task_1-4_model_theta_seed-{seed}.pt\")\n",
    "\n",
    "num_runs = 10\n",
    "pred_error_sds[seed] = onp.zeros((num_runs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20364ea0f988b89455c9685ea9cc451f",
     "grade": true,
     "grade_id": "cell-184b3cffa2fc5614",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.4: TRAIN MODEL HERE\"\"\"\n",
    "    for run in range(num_runs):\n",
    "        torch.manual_seed(seed=seed)\n",
    "        model_theta_seed = NeuralNetworkThetaSeed()\n",
    "        optimizer = torch.optim.SGD(model_theta_seed.parameters(), lr=1e-3)\n",
    "        # YOUR CODE HERE\n",
    "        # GPU\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model_theta_seed = model_theta_seed.to(device)\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            for i, data_train in enumerate(train_loader_theta):\n",
    "                inputs_train, labels_train = data_train[0].to(device), data_train[1].to(device)\n",
    "                est_th = model_theta_seed(inputs_train)\n",
    "                loss = loss_fn(est_th, labels_train)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        pred_error_sds[seed][run] = evaluate_model_test_data_theta(model_theta_seed.to(\"cpu\"), test_loader_theta)\n",
    "        print(f\"run {run+1} finished\")\n",
    "    \"\"\"TASK 1.4: END\"\"\"\n",
    "    print(\"seed:{} average prediction error:  {} variance:  {}\".format(seed, onp.mean(pred_error_sds[seed]), onp.var(pred_error_sds[seed]) ))\n",
    "\n",
    "    print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If working on CodeSpaces, run this cell before running the next model to free up memory\n",
    "if not AUTOGRADING:\n",
    "    model_theta_scripted = torch.jit.script(model_theta_seed)\n",
    "    # Save your models\n",
    "    model_theta_scripted.save(str(statedicts_dir / \"task_1-4_model_theta_seed0.pt\"))\n",
    "    model_theta_scripted.save(str(statedicts_dir / \"task_1-4_model_theta_seed1.pt\"))\n",
    "\n",
    "    %xdel train_loader_theta\n",
    "    %xdel val_loader_theta\n",
    "    %xdel test_loader_theta\n",
    "    %xdel model_theta_scripted\n",
    "\n",
    "    _, test_dataset_theta = load_test_dataset_dataloader(\n",
    "        str(datasets_dir / \"dataset_double_pendulum_test.npz\"),\n",
    "        _rng=init_rng,\n",
    "        model_type=\"theta\",\n",
    "    )\n",
    "\n",
    "    evaluate_model(\n",
    "        model_theta_seed,\n",
    "        test_dataset_theta,\n",
    "        model=\"theta\",\n",
    "        file=\"task_1-4_model_theta_prediction_error.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9ff2a2ed28bdb7bb19b1b5bde1f7d5a",
     "grade": false,
     "grade_id": "cell-27be995a7917e630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- What do you observe? (1p)\n",
    "\n",
    "- What is the benefit of seeding the pseudo-random generator in practice? **(1p)**\n",
    "\n",
    "Write your answers in the cell below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95a86a8351d6962fd6620a6712451725",
     "grade": true,
     "grade_id": "cell-47bf48a2d9c4af1d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: (1) If we set the seed for the model, the variance of the results of the model in multiple runs will stay 0, which means the parameters of the model stay same. (2) In this way, we are generating the same model with same parameters every time, we can eliminate the influence of the random seed to the model and better compare the effect of hyperparameters in different experiments.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08c900766c933fd0e86705af053ce509",
     "grade": false,
     "grade_id": "cell-cec950b501583524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.5: Spiking neural networks (15p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08ae3a1528be8f96f48c104867175721",
     "grade": false,
     "grade_id": "cell-3d456e0fbb95d0e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If our goal is to control the double pendulum, the angular velocity $\\dot{\\theta}$ is generally also required. However, temporal information cannot be extracted from individual images. We are going to utilize the temporal advantage of the spiking neural networks (SNN) to predict the angular velocity of each link. Instead of static individual images, we adopt event-based data as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4d5b26ce4148c3dd6acdaa59ed30062",
     "grade": false,
     "grade_id": "cell-013353c1c5418c4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Warm Up\n",
    "Use the Jupyter notebook `task_1-5_SNN_warmup.ipynb` to understand the neuron structure of SNNs, construct a LIF neuron model and a simple fully connected SNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "689db5dfe7020b9e10952d935936961a",
     "grade": false,
     "grade_id": "cell-ca0b905a64e10e55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the dataloader has been defined, and the two data sets `train_loader_snn` and `test_loader_snn` have been generated, which can be directly used to train the network. The two datasets are the same size. The batch_size has chosen 16. And we shuffle the dataset by setting shuffle to true. At the same time, to make the size of the data set just divisible by batch_size, we set drop_last to true to discard the last set of data that is less than one batch. At the same time, we did not set the validation set.\n",
    "\n",
    "Therefore, the size of each piece of data in dataloader is: Ôºàbatch_size: 16, time_step: 20, channels: 2, size: 32, size: 32Ôºâ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af1c68b5e06dd1d0eaa9687a29efc95c",
     "grade": false,
     "grade_id": "cell-98b1690578b3fdf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This part has to be same as task_1a_generate_data.ipynb\n",
    "train_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "train_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "test_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "test_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "\n",
    "TRAIN_NUM_DATA = len(train_th1_range) * len(train_th2_range)\n",
    "TEST_NUM_DATA = len(test_th1_range) * len(test_th2_range)\n",
    "NUM_SNN_DATA = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6328b8fae49aa7697c3cb31f20eb5aa0",
     "grade": false,
     "grade_id": "cell-7dbf1ba461ec8298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    train_set_snn = SNNDataset(\n",
    "        datasets_dir / \"event_based_data\" / \"train\",\n",
    "        TRAIN_NUM_DATA,\n",
    "        NUM_SNN_DATA,\n",
    "    )\n",
    "    train_loader_snn = DataLoader(\n",
    "        train_set_snn, batch_size=16, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    test_set_snn = SNNDataset(\n",
    "        datasets_dir / \"event_based_data\" / \"test\",\n",
    "        TEST_NUM_DATA,\n",
    "        NUM_SNN_DATA,\n",
    "    )\n",
    "    test_loader_snn = DataLoader(\n",
    "        test_set_snn, batch_size=16, shuffle=True, drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0648b8183773e05fb9c2d15bfb3be94e",
     "grade": false,
     "grade_id": "cell-62b53199c8d6ae6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Create the model (4p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27183a77bdecbca21d2971d3e70f3722",
     "grade": false,
     "grade_id": "cell-25520c2578c97471",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We create a class called `snnModel` extending `nn.Module`. Please fill this class to implement the model of SNNs. We adopt the LIF model for neurons.\n",
    "\n",
    "The structure of the network is like:\n",
    "\n",
    "* Start with a convolutional layer with 16 as the number of output channels, kernel size of `5x5`.\n",
    "* Then, add a max pooling layer with a pooling size of `4x4`.\n",
    "* Add the second convolutional layer with 16 as output channel size, kernel size of `3x3`.\n",
    "* Add the third convolutional layer with 16 as output channel size, kernel size of `3x3`.\n",
    "* All neurons use LIF model, and obtain the membrane potential in a recurrent way.\n",
    "* Flatten the membrane potential in the last layer and feed it into two fully connected layers with the ReLU activation fuction in between. We recommend the input size of the second fully connected layer is 640. The final output number must match the dimension of our target data which is 2.\n",
    "\n",
    "Meanwhile, for LIF model, we use `fast_sigmoid` function as the surrogate function, and the decay rate `beta` is 0.8. It is worth noting that we need to use the recurrent method to process event-based data. So,\n",
    "\n",
    "* We should use the for-loop to traverse each time step of the input event-based data. For the data of each time step, we can use the convolution operation to process the data as usual. Each convolution operation is followed by a layer of SNN neurons. Finally, the membrane potential of the last layer of all time steps is used as output. Therefore, the expected output format of the SNN part should be `[batch_size: 16, time_step: 20, conv_channel: (should be the channel size of the last convolutional layer), size: (output size), size: (output size)]`.\n",
    "* The first dimension of the input data is batch size, but not the time steps. So we need to transpose the input tensor first and then use for-loop to process it.\n",
    "* The final non-linear layer (two fully connected layers with ReLU) should be the conventional neurons instead of SNN neurons.\n",
    "* Do not forget to initialize the LIF neurons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4d92245dd0ca71e6a24aa18edffde7a",
     "grade": true,
     "grade_id": "cell-d96a62b92b1c8df6",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of model parameters:  1850578\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "class snnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(2, 16, 5) \n",
    "        self.pool = torch.nn.MaxPool2d(4)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.conv3 = torch.nn.Conv2d(16, 16, 3)\n",
    "        spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "        self.lif1 = snn.Leaky(beta=0.8, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.8, spike_grad=spike_grad)\n",
    "        self.lif3 = snn.Leaky(beta=0.8, spike_grad=spike_grad)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(144*20, 640)\n",
    "        self.linear2 = torch.nn.Linear(640, 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.time_steps = 20\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        mem3_record = []\n",
    "        \n",
    "        # x : 32*32*2 (input) -> 28*28*16 (conv1) -> 7*7*16 (pool) -> 5*5*16 (conv2) -> 3*3*16(conv3) -> 144*640(linear1 + relu) -> 640*2 (linear2)\n",
    "        for t in range(self.time_steps):\n",
    "            x_cur = self.conv1(x[:, t, :, :])\n",
    "            x_cur = self.pool(x_cur)\n",
    "            spk1, mem1 = self.lif1(x_cur, mem1)\n",
    "\n",
    "            x_cur = self.conv2(spk1)\n",
    "            spk2, mem2 = self.lif2(x_cur, mem2)\n",
    "            \n",
    "            x_cur = self.conv3(spk2)\n",
    "            # print(torch.allclose(x_cur[0], x_cur[1]))\n",
    "            spk3, mem3 = self.lif3(x_cur, mem3)\n",
    "            mem3_record.append(mem3)\n",
    "        x_cur = torch.stack(mem3_record, dim=1)\n",
    "        x_cur = self.flatten(x_cur)\n",
    "        # print(torch.allclose(x_cur[0:8], x_cur[8:16]))\n",
    "       #  print(x_cur.size())\n",
    "        x_cur = self.relu(self.linear1(x_cur))\n",
    "        y = self.linear2(x_cur)\n",
    "        return y\n",
    "\"\"\"TASK1.5: END\"\"\"\n",
    "\n",
    "model_snn = snnModel()\n",
    "total_params_snn = sum(p.numel() for p in model_snn.parameters())\n",
    "print(\"total number of model parameters: \", total_params_snn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffd0ee3e51ad67893f73f66391591ebb",
     "grade": false,
     "grade_id": "cell-7238196d33aa84de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Train the model (3p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d58888e29146a3cea2e25d539f95d6a",
     "grade": false,
     "grade_id": "cell-64f390c4e4d9ef2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Train the SNN model in the same way with other models. We recommend using `1e-3` as the learning rate and training the model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65f33d5f5980bdd44ea8220ca6ec08e5",
     "grade": false,
     "grade_id": "cell-733f37b346b1f159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_snn.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0539c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.616482734680176\n",
      "10.430536270141602\n",
      "15.96606731414795\n",
      "21.06249237060547\n",
      "17.79951286315918\n",
      "7.228617191314697\n",
      "9.728002548217773\n",
      "10.517072677612305\n",
      "10.255596160888672\n",
      "12.32732105255127\n",
      "9.495389938354492\n",
      "8.98714828491211\n",
      "7.92635440826416\n",
      "10.726591110229492\n",
      "8.873223304748535\n",
      "3.192913055419922\n",
      "7.351522445678711\n",
      "10.084579467773438\n",
      "5.757892608642578\n",
      "5.95216178894043\n",
      "2.106663227081299\n",
      "8.647176742553711\n",
      "4.046149253845215\n",
      "13.345032691955566\n",
      "2.6251449584960938\n",
      "5.222508430480957\n",
      "3.6907811164855957\n",
      "3.960984945297241\n",
      "11.330108642578125\n",
      "9.584328651428223\n",
      "13.159421920776367\n",
      "4.445817947387695\n",
      "5.050163269042969\n",
      "1.8312723636627197\n",
      "6.200928211212158\n",
      "4.644791126251221\n",
      "3.7452516555786133\n",
      "3.370759963989258\n",
      "5.835452079772949\n",
      "3.079028367996216\n",
      "4.56758975982666\n",
      "7.593442916870117\n",
      "5.901374816894531\n",
      "3.257965087890625\n",
      "5.906192302703857\n",
      "5.870291709899902\n",
      "3.8033447265625\n",
      "4.8882598876953125\n",
      "3.0984129905700684\n",
      "4.961668491363525\n",
      "2.3328614234924316\n",
      "5.333295822143555\n",
      "3.0594210624694824\n",
      "3.8740158081054688\n",
      "2.6806800365448\n",
      "3.5331082344055176\n",
      "3.1452834606170654\n",
      "3.1719226837158203\n",
      "5.39424467086792\n",
      "4.016422748565674\n",
      "4.588838577270508\n",
      "2.5156664848327637\n",
      "2.8481087684631348\n",
      "5.033234596252441\n",
      "4.09941291809082\n",
      "5.048229694366455\n",
      "3.515383005142212\n",
      "1.0081968307495117\n",
      "1.4225552082061768\n",
      "4.028873443603516\n",
      "2.848660945892334\n",
      "2.8734629154205322\n",
      "1.3152426481246948\n",
      "1.3803281784057617\n",
      "2.8060719966888428\n",
      "2.4486751556396484\n",
      "1.4465045928955078\n",
      "1.2630894184112549\n",
      "2.057877779006958\n",
      "2.737955093383789\n",
      "3.7728865146636963\n",
      "1.6053569316864014\n",
      "3.58909273147583\n",
      "3.496371269226074\n",
      "2.283141613006592\n",
      "2.1832828521728516\n",
      "1.690071940422058\n",
      "2.403585433959961\n",
      "3.246690511703491\n",
      "3.604409694671631\n",
      "3.4491171836853027\n",
      "3.980164051055908\n",
      "2.0333001613616943\n",
      "3.096687078475952\n",
      "1.8213934898376465\n",
      "2.0068366527557373\n",
      "1.473107099533081\n",
      "3.379093647003174\n",
      "2.232300043106079\n",
      "1.6421449184417725\n",
      "1.3685054779052734\n",
      "2.163273811340332\n",
      "3.198275089263916\n",
      "4.344390869140625\n",
      "1.1326056718826294\n",
      "1.6086918115615845\n",
      "1.9730286598205566\n",
      "1.8120763301849365\n",
      "3.1367151737213135\n",
      "2.2992172241210938\n",
      "3.357992649078369\n",
      "4.467995643615723\n",
      "2.7537641525268555\n",
      "1.8680343627929688\n",
      "2.6399996280670166\n",
      "1.6097757816314697\n",
      "0.9789395332336426\n",
      "3.550698757171631\n",
      "1.8176939487457275\n",
      "1.984510898590088\n",
      "0.49738338589668274\n",
      "2.318864345550537\n",
      "1.4419031143188477\n",
      "1.7119691371917725\n",
      "1.26027250289917\n",
      "1.092474341392517\n",
      "1.0995144844055176\n",
      "2.2184839248657227\n",
      "1.9071557521820068\n",
      "1.2994892597198486\n",
      "1.370416522026062\n",
      "1.5648307800292969\n",
      "1.7546261548995972\n",
      "3.012267589569092\n",
      "1.3952170610427856\n",
      "2.423841953277588\n",
      "1.2357726097106934\n",
      "2.135958671569824\n",
      "1.791043758392334\n",
      "1.4320073127746582\n",
      "1.318101406097412\n",
      "1.1709506511688232\n",
      "1.3296757936477661\n",
      "2.3559250831604004\n",
      "0.8422618508338928\n",
      "0.49387574195861816\n",
      "0.7417262196540833\n",
      "1.4391460418701172\n",
      "0.7147884964942932\n",
      "0.6022152900695801\n",
      "0.8362331390380859\n",
      "0.2843644618988037\n",
      "2.314256191253662\n",
      "1.8789548873901367\n",
      "0.4608176350593567\n",
      "0.7346556782722473\n",
      "0.7711639404296875\n",
      "1.1787992715835571\n",
      "1.665441870689392\n",
      "1.0389493703842163\n",
      "2.196181297302246\n",
      "1.4782030582427979\n",
      "2.6308279037475586\n",
      "2.1683638095855713\n",
      "1.1200050115585327\n",
      "0.6165982484817505\n",
      "2.040735960006714\n",
      "2.658071517944336\n",
      "1.385862112045288\n",
      "0.8872251510620117\n",
      "1.2486209869384766\n",
      "2.873288631439209\n",
      "1.681896448135376\n",
      "1.4089347124099731\n",
      "1.6079131364822388\n",
      "1.0321922302246094\n",
      "0.8770151138305664\n",
      "1.8794710636138916\n",
      "1.6488187313079834\n",
      "1.418212890625\n",
      "0.9958886504173279\n",
      "1.4371261596679688\n",
      "0.6936748027801514\n",
      "1.7023903131484985\n",
      "0.7620111107826233\n",
      "1.0512665510177612\n",
      "1.5805691480636597\n",
      "0.8995528221130371\n",
      "0.9546505212783813\n",
      "1.2958438396453857\n",
      "1.0047686100006104\n",
      "0.6661761403083801\n",
      "0.6499300599098206\n",
      "0.9552305936813354\n",
      "0.6862754821777344\n",
      "1.4156827926635742\n",
      "0.502660870552063\n",
      "1.006270408630371\n",
      "3.3509931564331055\n",
      "0.9280786514282227\n",
      "0.615483820438385\n",
      "1.260502815246582\n",
      "0.9721295237541199\n",
      "1.0048127174377441\n",
      "0.9050509333610535\n",
      "1.0725282430648804\n",
      "1.166560173034668\n",
      "2.3998563289642334\n",
      "0.903007984161377\n",
      "0.5552622079849243\n",
      "0.4310121536254883\n",
      "0.7698364853858948\n",
      "1.3172416687011719\n",
      "0.606753945350647\n",
      "0.8170436024665833\n",
      "1.4002394676208496\n",
      "0.8902161717414856\n",
      "0.5231378674507141\n",
      "0.5889948606491089\n",
      "0.8080300092697144\n",
      "0.7737303972244263\n",
      "0.5137765407562256\n",
      "1.3874226808547974\n",
      "1.3377052545547485\n",
      "1.4967018365859985\n",
      "1.30303955078125\n",
      "0.587745726108551\n",
      "2.3190667629241943\n",
      "1.659149408340454\n",
      "0.8916605114936829\n",
      "1.0770188570022583\n",
      "1.397979974746704\n",
      "2.0231869220733643\n",
      "0.5356179475784302\n",
      "2.607377052307129\n",
      "0.7970828413963318\n",
      "1.0083796977996826\n",
      "1.1355624198913574\n",
      "0.4996456503868103\n",
      "0.835668683052063\n",
      "1.4866644144058228\n",
      "0.3513926863670349\n",
      "1.6076382398605347\n",
      "1.147792100906372\n",
      "0.7585240006446838\n",
      "0.7189862728118896\n",
      "0.9193688631057739\n",
      "0.8051379919052124\n",
      "0.5172324776649475\n",
      "0.586688756942749\n",
      "1.152029037475586\n",
      "1.5902342796325684\n",
      "1.4149436950683594\n",
      "0.646488606929779\n",
      "1.3634085655212402\n",
      "0.9255689382553101\n",
      "1.408808708190918\n",
      "0.7570687532424927\n",
      "1.0008562803268433\n",
      "1.2838059663772583\n",
      "1.4587936401367188\n",
      "1.2386436462402344\n",
      "1.3411519527435303\n",
      "1.4246830940246582\n",
      "0.9077175259590149\n",
      "1.163448691368103\n",
      "0.753074049949646\n",
      "0.9247519373893738\n",
      "1.133558988571167\n",
      "1.4182770252227783\n",
      "1.2335212230682373\n",
      "1.0199521780014038\n",
      "0.5465840101242065\n",
      "0.9354797601699829\n",
      "0.6820341348648071\n",
      "1.134419322013855\n",
      "1.045867919921875\n",
      "0.8681585192680359\n",
      "0.3500570058822632\n",
      "1.6795953512191772\n",
      "0.6543733477592468\n",
      "0.9906437397003174\n",
      "0.7225617170333862\n",
      "1.4885656833648682\n",
      "0.3789268732070923\n",
      "0.37757423520088196\n",
      "0.9995501041412354\n",
      "1.2993521690368652\n",
      "0.5820968747138977\n",
      "1.207869529724121\n",
      "0.4970083236694336\n",
      "1.2497138977050781\n",
      "0.5501478314399719\n",
      "0.9436126351356506\n",
      "0.7224373817443848\n",
      "1.516222596168518\n",
      "1.0422767400741577\n",
      "1.7353475093841553\n",
      "0.7939868569374084\n",
      "0.946979820728302\n",
      "1.4791162014007568\n",
      "1.916552186012268\n",
      "0.4325440227985382\n",
      "1.1548478603363037\n",
      "0.5092269778251648\n",
      "0.7167624831199646\n",
      "0.7343806028366089\n",
      "0.6497888565063477\n",
      "0.5042692422866821\n",
      "0.9801929593086243\n",
      "0.5279219150543213\n",
      "0.9794762134552002\n",
      "0.795673131942749\n",
      "1.109074592590332\n",
      "1.3592005968093872\n",
      "0.5707904696464539\n",
      "0.4550844728946686\n",
      "0.8116223216056824\n",
      "0.7638079524040222\n",
      "1.0152446031570435\n",
      "0.8173990249633789\n",
      "0.9857174158096313\n",
      "0.2988629937171936\n",
      "0.9213900566101074\n",
      "1.0618185997009277\n",
      "1.0143325328826904\n",
      "0.5845497846603394\n",
      "1.0583927631378174\n",
      "0.8897597789764404\n",
      "0.5076165199279785\n",
      "0.9776227474212646\n",
      "0.954785943031311\n",
      "0.2598860561847687\n",
      "0.6470927000045776\n",
      "0.3729473948478699\n",
      "0.49369916319847107\n",
      "0.5118974447250366\n",
      "0.7106465697288513\n",
      "0.8245664834976196\n",
      "0.9117112159729004\n",
      "0.42587748169898987\n",
      "0.5207063555717468\n",
      "0.9341239333152771\n",
      "0.5406613349914551\n",
      "0.4929235577583313\n",
      "0.8717776536941528\n",
      "0.25696688890457153\n",
      "0.9227404594421387\n",
      "0.4901248514652252\n",
      "0.4082680344581604\n",
      "0.4879370927810669\n",
      "0.36399468779563904\n",
      "0.3486550450325012\n",
      "0.581896960735321\n",
      "0.3626537621021271\n",
      "0.6276710033416748\n",
      "0.8333480954170227\n",
      "0.4651110768318176\n",
      "0.44959813356399536\n",
      "0.9158884286880493\n",
      "0.5133331418037415\n",
      "0.8808597326278687\n",
      "0.8748828768730164\n",
      "1.1666072607040405\n",
      "1.3214956521987915\n",
      "0.6127989888191223\n",
      "0.7432740926742554\n",
      "0.6895542144775391\n",
      "1.2062852382659912\n",
      "1.0268237590789795\n",
      "0.9960595965385437\n",
      "0.9160394668579102\n",
      "0.5541293025016785\n",
      "1.5048930644989014\n",
      "0.4810904860496521\n",
      "0.6586873531341553\n",
      "0.21971194446086884\n",
      "0.8929816484451294\n",
      "0.525933027267456\n",
      "0.4919166564941406\n",
      "0.33327972888946533\n",
      "1.0606071949005127\n",
      "0.32232117652893066\n",
      "0.6671426892280579\n",
      "0.7157043814659119\n",
      "0.5778179168701172\n",
      "1.0952986478805542\n",
      "0.33089837431907654\n",
      "1.0515810251235962\n",
      "0.8548679351806641\n",
      "0.40964406728744507\n",
      "0.9038543105125427\n",
      "0.3745292127132416\n",
      "0.9779300689697266\n",
      "0.3026389479637146\n",
      "1.0332214832305908\n",
      "0.5739924907684326\n",
      "1.1795849800109863\n",
      "0.8672971725463867\n",
      "1.015949010848999\n",
      "0.7661113739013672\n",
      "0.5054745674133301\n",
      "0.3837031126022339\n",
      "0.685999870300293\n",
      "0.33329349756240845\n",
      "0.5197649598121643\n",
      "0.521332859992981\n",
      "1.183244228363037\n",
      "0.4797995090484619\n",
      "0.8122244477272034\n",
      "0.6929600238800049\n",
      "0.6036554574966431\n",
      "0.6604158282279968\n",
      "0.5593089461326599\n",
      "0.30965983867645264\n",
      "0.8016659021377563\n",
      "0.5777318477630615\n",
      "0.9345408082008362\n",
      "0.44534337520599365\n",
      "0.2702406644821167\n",
      "0.64566969871521\n",
      "0.7921761274337769\n",
      "0.5888233184814453\n",
      "0.5715954303741455\n",
      "0.6782206296920776\n",
      "1.0545220375061035\n",
      "0.6228808164596558\n",
      "0.4215700030326843\n",
      "0.6870281100273132\n",
      "0.6798474192619324\n",
      "0.3148708641529083\n",
      "1.223978042602539\n",
      "0.21782182157039642\n",
      "0.4282434284687042\n",
      "0.4589608907699585\n",
      "0.814498245716095\n",
      "0.542812705039978\n",
      "0.6451345086097717\n",
      "0.6469705104827881\n",
      "1.178649663925171\n",
      "0.4403451681137085\n",
      "0.5887708067893982\n",
      "0.6849251985549927\n",
      "1.2127931118011475\n",
      "0.6456779837608337\n",
      "0.6105682849884033\n",
      "0.920504093170166\n",
      "0.8119648694992065\n",
      "0.2627909779548645\n",
      "0.743757963180542\n",
      "0.7907216548919678\n",
      "0.48280560970306396\n",
      "1.0709893703460693\n",
      "1.0227165222167969\n",
      "0.4542573094367981\n",
      "0.8839901089668274\n",
      "1.5054759979248047\n",
      "1.164091944694519\n",
      "0.9356266260147095\n",
      "0.6713143587112427\n",
      "0.5763968229293823\n",
      "0.38006478548049927\n",
      "1.2369937896728516\n",
      "0.3732624351978302\n",
      "0.6033833026885986\n",
      "0.6528974771499634\n",
      "1.1117420196533203\n",
      "0.5189372301101685\n",
      "0.6298303604125977\n",
      "0.3741384744644165\n",
      "0.6854000091552734\n",
      "0.8584134578704834\n",
      "1.348379135131836\n",
      "1.9866158962249756\n",
      "1.124067783355713\n",
      "0.38571712374687195\n",
      "0.5874365568161011\n",
      "1.788268804550171\n",
      "0.7603859901428223\n",
      "1.190130591392517\n",
      "0.534188985824585\n",
      "0.7452490329742432\n",
      "0.5431371927261353\n",
      "0.7799882888793945\n",
      "1.0869075059890747\n",
      "1.1312066316604614\n",
      "0.4665287137031555\n",
      "0.8529363870620728\n",
      "0.5805293321609497\n",
      "0.8313387632369995\n",
      "0.9885790348052979\n",
      "0.9687942862510681\n",
      "0.7642413377761841\n",
      "0.8138803839683533\n",
      "0.5063035488128662\n",
      "1.1797999143600464\n",
      "0.5446715354919434\n",
      "0.39437955617904663\n",
      "1.4119282960891724\n",
      "0.6809725761413574\n",
      "0.5334895849227905\n",
      "0.8473497033119202\n",
      "0.7058756351470947\n",
      "1.0413861274719238\n",
      "0.6175042390823364\n",
      "0.9039080739021301\n",
      "0.7935265898704529\n",
      "0.9460222125053406\n",
      "0.8121429681777954\n",
      "0.7363469004631042\n",
      "0.9568093419075012\n",
      "0.5382142066955566\n",
      "0.36720114946365356\n",
      "0.6547233462333679\n",
      "0.4640612304210663\n",
      "0.700423002243042\n",
      "0.41838979721069336\n",
      "1.107595443725586\n",
      "0.9291836619377136\n",
      "0.41486048698425293\n",
      "1.0590918064117432\n",
      "0.3538673520088196\n",
      "1.0113964080810547\n",
      "0.7584189772605896\n",
      "0.6902366876602173\n",
      "0.48833364248275757\n",
      "0.491803377866745\n",
      "0.9664543867111206\n",
      "0.984708309173584\n",
      "0.5358594655990601\n",
      "0.48033004999160767\n",
      "1.035097599029541\n",
      "0.33324337005615234\n",
      "0.5900061726570129\n",
      "1.403390884399414\n",
      "0.4490290582180023\n",
      "0.4298481345176697\n",
      "0.719602108001709\n",
      "1.0521814823150635\n",
      "1.132556438446045\n",
      "1.2061617374420166\n",
      "0.9639947414398193\n",
      "0.9419943690299988\n",
      "0.8320115208625793\n",
      "0.3137037754058838\n",
      "0.6155397295951843\n",
      "1.2099469900131226\n",
      "0.8127951622009277\n",
      "0.5936323404312134\n",
      "0.3125159442424774\n",
      "0.5125001668930054\n",
      "0.7650517225265503\n",
      "1.2101941108703613\n",
      "1.0661022663116455\n",
      "1.149162769317627\n",
      "0.48015421628952026\n",
      "0.370159387588501\n",
      "0.3507336974143982\n",
      "0.8119515776634216\n",
      "0.7649170160293579\n",
      "0.5249479413032532\n",
      "0.5670119524002075\n",
      "1.141756296157837\n",
      "0.47099560499191284\n",
      "1.002239465713501\n",
      "0.7722233533859253\n",
      "0.9512738585472107\n",
      "0.5923980474472046\n",
      "0.6979331970214844\n",
      "0.5097704529762268\n",
      "0.5631897449493408\n",
      "1.1349992752075195\n",
      "0.6265082359313965\n",
      "0.6033669710159302\n",
      "0.4178260564804077\n",
      "0.4733830690383911\n",
      "0.3010629415512085\n",
      "0.7767645120620728\n",
      "0.5691173672676086\n",
      "0.6134149432182312\n",
      "0.624200701713562\n",
      "0.42503881454467773\n",
      "0.8534325361251831\n",
      "0.48915988206863403\n",
      "1.3188270330429077\n",
      "0.4076460599899292\n",
      "0.434262752532959\n",
      "0.6956357359886169\n",
      "0.5151089429855347\n",
      "0.6862308979034424\n",
      "0.6514231562614441\n",
      "0.5871021151542664\n",
      "0.9013876914978027\n",
      "0.9389610290527344\n",
      "1.0005834102630615\n",
      "0.6817818880081177\n",
      "0.478298157453537\n",
      "0.45778828859329224\n",
      "0.49980178475379944\n",
      "0.9638276100158691\n",
      "0.44607436656951904\n",
      "0.7654657363891602\n",
      "0.4539734125137329\n",
      "0.3895457983016968\n",
      "0.5917249917984009\n",
      "0.40041977167129517\n",
      "0.6084194779396057\n",
      "0.37066036462783813\n",
      "0.6933846473693848\n",
      "0.5606961250305176\n",
      "0.6595326662063599\n",
      "0.4727701246738434\n",
      "0.34803637862205505\n",
      "0.43765464425086975\n",
      "0.7135001420974731\n",
      "0.8378786444664001\n",
      "0.5865757465362549\n",
      "0.7492659091949463\n",
      "1.002062201499939\n",
      "0.5922890305519104\n",
      "0.31098294258117676\n",
      "0.36693403124809265\n",
      "0.5169023871421814\n",
      "0.9502736330032349\n",
      "0.35297948122024536\n",
      "0.40834981203079224\n",
      "0.5541767477989197\n",
      "0.5075985193252563\n",
      "0.3872710168361664\n",
      "1.3002312183380127\n",
      "0.6306665539741516\n",
      "0.4351480007171631\n",
      "0.5053669214248657\n",
      "0.6949831247329712\n",
      "0.4749112129211426\n",
      "0.40355491638183594\n",
      "0.639664351940155\n",
      "0.3316945433616638\n",
      "0.3908252418041229\n",
      "0.5074334144592285\n",
      "0.8664544820785522\n",
      "0.27205175161361694\n",
      "0.3306308388710022\n",
      "0.7037597894668579\n",
      "0.1599465012550354\n",
      "0.8500909805297852\n",
      "0.5556843876838684\n",
      "0.4800393581390381\n",
      "0.26431819796562195\n",
      "0.6009544730186462\n",
      "0.4767051935195923\n",
      "0.3606167137622833\n",
      "1.015841007232666\n",
      "0.5081086158752441\n",
      "0.5274466276168823\n",
      "0.7855743169784546\n",
      "0.6816921234130859\n",
      "0.3539887070655823\n",
      "0.731214702129364\n",
      "0.3891678750514984\n",
      "0.610950231552124\n",
      "0.3261641561985016\n",
      "0.35909759998321533\n",
      "0.3296535611152649\n",
      "0.40396857261657715\n",
      "0.41397595405578613\n",
      "1.2907332181930542\n",
      "0.738923192024231\n",
      "1.4144620895385742\n",
      "0.6810935735702515\n",
      "0.7678948044776917\n",
      "0.7785346508026123\n",
      "0.40404361486434937\n",
      "0.4447419047355652\n",
      "0.45296376943588257\n",
      "0.5539423823356628\n",
      "0.5677962303161621\n",
      "0.5146473050117493\n",
      "0.3166821599006653\n",
      "0.9731989502906799\n",
      "0.2357095628976822\n",
      "0.3694021701812744\n",
      "0.47718942165374756\n",
      "0.8043817281723022\n",
      "0.1940080225467682\n",
      "0.40418583154678345\n",
      "0.5516055822372437\n",
      "0.44863757491111755\n",
      "0.5782620906829834\n",
      "0.6817930340766907\n",
      "0.1961822509765625\n",
      "0.5374094247817993\n",
      "0.5079679489135742\n",
      "0.44922709465026855\n",
      "0.5209248065948486\n",
      "0.8896763324737549\n",
      "0.21844765543937683\n",
      "1.621273159980774\n",
      "0.4059971272945404\n",
      "0.5545278787612915\n",
      "0.8882830739021301\n",
      "0.5253294110298157\n",
      "0.3796502947807312\n",
      "0.6617906093597412\n",
      "0.5344059467315674\n",
      "0.40588316321372986\n",
      "0.18899214267730713\n",
      "0.4907669723033905\n",
      "0.3040156066417694\n",
      "0.6571863293647766\n",
      "0.8793766498565674\n",
      "0.48484817147254944\n",
      "0.7601867914199829\n",
      "0.35781851410865784\n",
      "0.39462143182754517\n",
      "0.4541928768157959\n",
      "0.7833588123321533\n",
      "0.33926093578338623\n",
      "0.2522575259208679\n",
      "0.48564696311950684\n",
      "0.6745809316635132\n",
      "0.8816942572593689\n",
      "0.5167841911315918\n",
      "0.8500958681106567\n",
      "0.3053727149963379\n",
      "0.457168310880661\n",
      "0.24228839576244354\n",
      "0.6189762949943542\n",
      "0.6825498342514038\n",
      "0.583968997001648\n",
      "1.019624948501587\n",
      "0.2970811724662781\n",
      "0.3861839771270752\n",
      "0.9315725564956665\n",
      "0.32747411727905273\n",
      "0.24258364737033844\n",
      "0.7830561399459839\n",
      "0.47203320264816284\n",
      "0.5236978530883789\n",
      "0.7995912432670593\n",
      "0.3701980710029602\n",
      "0.5206184387207031\n",
      "0.6567226648330688\n",
      "0.3583607077598572\n",
      "0.46540921926498413\n",
      "0.29916858673095703\n",
      "0.48408323526382446\n",
      "0.7724579572677612\n",
      "0.38258567452430725\n",
      "0.7039528489112854\n",
      "0.7853660583496094\n",
      "0.47425907850265503\n",
      "0.5499900579452515\n",
      "0.5747621059417725\n",
      "1.2799330949783325\n",
      "0.4059883654117584\n",
      "0.48047196865081787\n",
      "1.0579792261123657\n",
      "0.5267972350120544\n",
      "0.2963625192642212\n",
      "0.9402634501457214\n",
      "1.0045270919799805\n",
      "0.412757933139801\n",
      "0.8622283935546875\n",
      "0.5780779123306274\n",
      "0.6528670787811279\n",
      "0.3411070704460144\n",
      "0.6013771295547485\n",
      "0.6035776138305664\n",
      "0.6116724610328674\n",
      "0.4762393832206726\n",
      "0.4534885585308075\n",
      "0.5104106664657593\n",
      "0.2872987985610962\n",
      "0.5323293209075928\n",
      "0.4388197660446167\n",
      "0.5116756558418274\n",
      "0.18820296227931976\n",
      "0.18983054161071777\n",
      "0.34580013155937195\n",
      "0.3877761662006378\n",
      "0.6257412433624268\n",
      "0.6912291049957275\n",
      "0.5768862962722778\n",
      "0.271521657705307\n",
      "0.3783080577850342\n",
      "0.23377440869808197\n",
      "0.34803301095962524\n",
      "0.6496831774711609\n",
      "0.24071970582008362\n",
      "0.34657102823257446\n",
      "0.2889848053455353\n",
      "0.28494855761528015\n",
      "0.3500671982765198\n",
      "0.2980305552482605\n",
      "0.6385577917098999\n",
      "0.24590691924095154\n",
      "0.4972761869430542\n",
      "0.9414889812469482\n",
      "0.544066309928894\n"
     ]
    }
   ],
   "source": [
    "onp.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if not AUTOGRADING:\n",
    "    \"\"\"TASK 1.5: TRAIN MODEL HERE\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_snn = model_snn.to(device)\n",
    "    for _ in range(num_epochs):\n",
    "        for i, data_train in enumerate(train_loader_snn):\n",
    "            inputs_train, labels_train = data_train[0].to(device), data_train[1].to(device)\n",
    "            est_th = model_snn(inputs_train)\n",
    "            # if i % 10 == 0:  print(est_th)\n",
    "            # print(labels_train)\n",
    "            loss = loss_fn(est_th, labels_train)\n",
    "            if i % 10 == 0: print(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                # pred_error_cnn[run] = evaluate_model_test_data_cnn(model_cnn, test_loader_cnn)\n",
    "    # print(\"average prediction error: \", onp.mean(pred_error_cnn))\n",
    "    print(\"Finished Training\")\n",
    "    \"\"\"TASK 1.5: END\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e55a9e0a13ac07c59185f30a9ae45ef6",
     "grade": false,
     "grade_id": "cell-ff2497b66bbcf9f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss of the model on the test dataset is: 0.5969758863384659\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the SNN model with test data\n",
    "if not AUTOGRADING:\n",
    "    torch.save(model_snn.state_dict(), str(statedicts_dir / \"task_1-5_model_snn.pt\"))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_snn = model_snn.eval()\n",
    "        model_snn = model_snn.to(\"cpu\")\n",
    "        print_loss = 0.0\n",
    "        count = 0\n",
    "        for i, (events, targets) in enumerate(test_loader_snn):\n",
    "            output = model_snn(events)\n",
    "            loss = loss_fn(output, targets)\n",
    "            print_loss += loss.item()\n",
    "            count = count + 1\n",
    "\n",
    "        print_loss = print_loss / count\n",
    "        print(f\"The MSE loss of the model on the test dataset is: {print_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ee4b4860a9462b1cb64b2b659d6c119",
     "grade": false,
     "grade_id": "cell-501c8e5f33a32e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5 - Analysis of results (8p)\n",
    "\n",
    "Does your loss decrease step by step? During the training process, is the training speed faster or slower comparing to CNN and why? Please analyse the advantages and disadvantages of SNN. **(8p)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cffd86a98bfc91a4cfec7158d8ccd88b",
     "grade": true,
     "grade_id": "cell-b9f9afb31f989574",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANS: (1) Yes, the loss is decreasing over iterations. (2) It is hard to tell if it is slower since we have no strict experiment to test the training speed of the two different networks, however, compared to pure CNN model, the SNN model can be regarded as CNN with a time-varying activation layer following the Convolution layers, it should be slower because the additional layer takes more computation. (3) The advantage of SNN is that it can learn the information from a series of input data. If we want to predict a value that is time-sensitive, SNN might be a good approach. (4) The disadvantage of SNN is that it has artificial derivative -- the back propagation process may not guarantee the optimal direction of the gradient. Also, the information of SNN lies in the frequency of spikes, we need to interpret the output properly. Here we use a Fully-connect Layer as the decoder, which demands more computation power.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c003857f227f761f54e3c6639e434e23cf463710137940f40452d094a979d43a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit ('ics': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
