{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"Shan Gao\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"5711002\"\n",
    "STUDENT_1_NETID = \"samgao\"\n",
    "STUDENT_1_EMAIL = \"S.Gao-9@student.tudelft.nl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1dc46e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task 1.0 - Generate the datasets (0p)\n",
    "\n",
    "**Authors:** TomÃ¡s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "### NOTE: This notebook is a replacement for the SNN-part in `task_1a_generate_data.ipynb`\n",
    "\n",
    "Due to the memory limitation of GitHub Codespaces, we recommend using this notebook instead to generate the **SNN** data. The procedure of generating data is exactly the same as the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a5c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import jit, random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import os\n",
    "from pathlib import Path\n",
    "from progressbar import progressbar\n",
    "from typing import Dict\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# folder to save the dataset to\n",
    "datasets_folder = Path(\"datasets\")\n",
    "datasets_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717eb78",
   "metadata": {},
   "source": [
    "## Generating simulated event-based dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee18586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset = draw_robot_snn(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d02a5",
   "metadata": {},
   "source": [
    "A simulated event-based image of a double pendulum is generated in the following cell, which is used for the training part in task 1.5. We use the same framework as in the RGB image generation section in the previous steps. However, event-based data requires the image itself and its dynamic transformation in continuous time. Therefore, we need to generate more data than in the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_sim_data_to_dataset_snn(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    _sim_idx: int,\n",
    "    _sim_ts: Dict[str, jnp.ndarray],\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    _dataset[\"th_curr_ss\"] = (\n",
    "        _dataset[\"th_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_curr_ss\"] = (\n",
    "        _dataset[\"th_d_curr_ss\"].at[_sim_idx].set(_sim_ts[\"th_d_ts\"][0])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[_sim_idx].set(_sim_ts[\"x_eb_ts\"][0])\n",
    "    _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[_sim_idx].set(_sim_ts[\"x_ts\"][0])\n",
    "\n",
    "    # Windowed data for SNN\n",
    "    _dataset[\"th_window_snn\"] = (\n",
    "        _dataset[\"th_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"th_d_window_snn\"] = (\n",
    "        _dataset[\"th_d_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"th_d_ts\"])\n",
    "    )\n",
    "\n",
    "    _dataset[\"x_eb_ts_window_snn\"] = (\n",
    "        _dataset[\"x_eb_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_eb_ts\"])\n",
    "    )\n",
    "    _dataset[\"x_ts_window_snn\"] = (\n",
    "        _dataset[\"x_ts_window_snn\"].at[_sim_idx, :, :].set(_sim_ts[\"x_ts\"])\n",
    "    )\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "@jit\n",
    "def generate_data_point(ic, _rng, _t_ts):\n",
    "    \"\"\"\n",
    "    Generates a data point for the state of the robot from a given angle.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # for ic_idx in range(initial_conditions, 1):\n",
    "\n",
    "    _rng, subkey1, subkey2 = random.split(_rng, 3)\n",
    "\n",
    "    max_th_d = 1 * jnp.pi\n",
    "\n",
    "    _th_d_0 = onp.array([max_th_d, max_th_d])\n",
    "    _sim_ts = simulate_robot(rp=ROBOT_PARAMS, t_ts=_t_ts, th_0=ic, th_d_0=_th_d_0)\n",
    "    return _sim_ts, _rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609c7c3",
   "metadata": {},
   "source": [
    "A train set and a test set are saved separately in the following cell. We could use the `train/test_th1/2_range` parameter to adjust the links' simulation range, which also affects the amount of generated data. Currently, it could generate 120 groups of training data and 120 groups of test data randomly. For each dataset, it contains 1010 continuous-time images, which will be used in the subsequent step of converting to event-based data. Due to the time-consuming steps of rendering and saving images (currently 15-20 minutes to generate two datasets), we do not recommend generating very large datasets or using larger image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe54767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% (0 of 120) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulation data for the SNN training set ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samgao1999/anaconda3/envs/ics/lib/python3.10/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float64 to dtype=float32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "100% (120 of 120) |######################| Elapsed Time: 0:00:08 Time:  0:00:08\n",
      "  1% (2 of 120) |                        | Elapsed Time: 0:00:00 ETA:   0:00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulation data for the SNN test set ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (120 of 120) |######################| Elapsed Time: 0:00:07 Time:  0:00:07\n",
      "  0% (0 of 120) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering images of the robot for the SNN training set ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (120 of 120) |######################| Elapsed Time: 0:00:47 Time:  0:00:47\n",
      "  0% (0 of 120) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering images of the robot for the SNN test set ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (120 of 120) |######################| Elapsed Time: 0:00:46 Time:  0:00:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start save the images to the file:\n",
      "save successfully!\n"
     ]
    }
   ],
   "source": [
    "# initialize random number generator\n",
    "key = random.PRNGKey(seed=42)\n",
    "\n",
    "# simulation parameters\n",
    "sim_duration = 6.06\n",
    "sim_dt = 6e-2\n",
    "img_size = 32\n",
    "# Since the big O is not good compared to the size of dataset,\n",
    "# Run this multiple times for different sections of the first link,\n",
    "# then bring them together in the training file.\n",
    "train_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "train_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "test_th1_range = jnp.arange(-jnp.pi / 6.0, jnp.pi / 6.0, jnp.pi / 30.0)\n",
    "test_th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 6.0)\n",
    "\n",
    "\n",
    "# initial_conditions = jnp.array([th_range, th_range])\n",
    "train_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(train_th1_range, train_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "test_initial_conditions = jnp.array(\n",
    "    jnp.meshgrid(test_th1_range, test_th2_range)\n",
    ").T.reshape(-1, 2)\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# set global variables\n",
    "TRAIN_NUM_DATA = len(train_th1_range) * len(train_th2_range)\n",
    "TEST_NUM_DATA = len(test_th1_range) * len(test_th2_range)\n",
    "NUM_SNN_DATA = 5\n",
    "\n",
    "\n",
    "trainset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TRAIN_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TRAIN_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TRAIN_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TRAIN_NUM_DATA, 101, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "testset = {\n",
    "    \"dt_ss\": sim_dt * jnp.ones(TEST_NUM_DATA, dtype=jnp.float32),\n",
    "    \"th_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_window_snn\": jnp.zeros((TEST_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"th_d_curr_ss\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"th_d_window_snn\": jnp.zeros((TEST_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_ts\": jnp.zeros((TEST_NUM_DATA, 2), dtype=jnp.float32),\n",
    "    \"x_eb_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"x_ts_window_snn\": jnp.zeros((TEST_NUM_DATA, 101, 2), dtype=jnp.float32),\n",
    "    \"th_pix_curr\": jnp.zeros((TEST_NUM_DATA, img_size, img_size, 3), dtype=jnp.float32),\n",
    "    \"th_pix_window_snn\": jnp.zeros(\n",
    "        (TEST_NUM_DATA, 101, img_size, img_size, 3), dtype=jnp.float32\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Generating simulation data for the SNN training set ...\")\n",
    "for sim_idx in progressbar(range(TRAIN_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(train_initial_conditions[sim_idx], key, t_ts)\n",
    "    trainset = save_sim_data_to_dataset_snn(trainset, sim_idx, sim_ts)\n",
    "\n",
    "print(\"Generating simulation data for the SNN test set ...\")\n",
    "for sim_idx in progressbar(range(TEST_NUM_DATA)):\n",
    "    sim_ts, key = generate_data_point(test_initial_conditions[sim_idx], key, t_ts)\n",
    "    testset = save_sim_data_to_dataset_snn(testset, sim_idx, sim_ts)\n",
    "\n",
    "print(\"Rendering images of the robot for the SNN training set ...\")\n",
    "trainset = save_image_data_to_dataset_snn(trainset, ROBOT_PARAMS)\n",
    "print(\"Rendering images of the robot for the SNN test set ...\")\n",
    "testset = save_image_data_to_dataset_snn(testset, ROBOT_PARAMS)\n",
    "\n",
    "print(f\"Start save the images to the file:\")\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\"), **trainset\n",
    ")\n",
    "jnp.savez(file=str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\"), **testset)\n",
    "print(f\"save successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6d394",
   "metadata": {},
   "source": [
    "### Transfer RGB image data into simulated event-based data\n",
    "We got training and test set in the previous generation step. Each dataset contains 120 consecutive sets of still images. Each set contains 1010 images. In the following steps, we will use these static images to simulate event-based data.\n",
    "\n",
    "Event-based data can only capture pixel changes. We will compare every two consecutive images. If the pixel goes from dark to bright, the event data of the first channel is set to 1. Conversely, if the pixel goes from bright to dark, the second channel's event data is set to 1. To capture noticeable pixel changes, we sample these 1010 images at intervals of 10. Ultimately, we can get 101 static images, which means we will get 100 event-based data containing pixel changes. We use 20 as the time step for each event-based data. Finally, we could obtain five event-based data from each group. The size of generated event-based data is: `[time_step: 20, channels: 2, size: 32, size: 32]`. They could be fed directly to SNNs.\n",
    "\n",
    "These event-based data will be saved seperately in the files named `train` and `test` in .pt format. In the following steps, we will use `torch.load()` method to read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1eb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_train.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TRAIN_NUM_DATA, NUM_SNN_DATA)\n",
    "    train_set_dir = datasets_folder / \"event_based_data\" / \"train\"\n",
    "    if train_set_dir.exists():\n",
    "        if os.path.getsize(train_set_dir) == 0:\n",
    "            os.removedirs(train_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(train_set_dir)\n",
    "    os.makedirs(train_set_dir)\n",
    "\n",
    "    divide_and_save_data(\n",
    "        snn_data, velocity, TRAIN_NUM_DATA, NUM_SNN_DATA, train_set_dir\n",
    "    )\n",
    "\n",
    "\n",
    "def testset_transform_to_snn(datasets_folder):\n",
    "    velocity, observation = read_data(\n",
    "        str(datasets_folder / \"dataset_double_pendulum_snn_test.npz\")\n",
    "    )\n",
    "\n",
    "    snn_data = generate_snn_data(observation, TEST_NUM_DATA, NUM_SNN_DATA)\n",
    "    test_set_dir = datasets_folder / \"event_based_data\" / \"test\"\n",
    "    if test_set_dir.exists():\n",
    "        if os.path.getsize(test_set_dir) == 0:\n",
    "            os.removedirs(test_set_dir)\n",
    "        else:\n",
    "            shutil.rmtree(test_set_dir)\n",
    "    os.makedirs(test_set_dir)\n",
    "\n",
    "    divide_and_save_data(snn_data, velocity, TEST_NUM_DATA, NUM_SNN_DATA, test_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02fcdc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform RGB sequential images into event-based data\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transform RGB sequential images into event-based data\")\n",
    "trainset_transform_to_snn(datasets_folder)\n",
    "testset_transform_to_snn(datasets_folder)\n",
    "print(f\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253ce76",
   "metadata": {},
   "source": [
    "### Show examples of SNN data\n",
    "Two examples of event-based data are printed as `.gif` in this section. The yellow and purple edges represent two channels in the event-based data. We can see how the pendulum changes during these 20 time steps. Therefore, the temporal characteristics of event-based data are implied in it. SNN will process this data in the form of recurrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b3fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACqklEQVR4nO3dwU3bYBiAYVOxCKJDsAkrcEMVc6CqN1ZgBDbgmAFA3FjDPQOWaoId86bPc4wC+g+vPvmT4+RkHMdxgJgfWx8A9iFckoRLknBJEi5JwiVJuCQJlyThknQ6941nf27XPAcMwzAML9c3s95n4pIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSTrd+gDH4uevxw+vPbzuZv3t+f3Vwqc5fiYuScIlSbgkCZcky9mKppau58u7DU5yfExckoRLknBJEi5JlrMVTd1NGy4Pf45jZOKSJFyShEuSa9xv4P1NCZ8W+zcTlyThkiRckoRLkuVsIU+/Lz68NnkDgkWYuCQJlyThkiRckixnB+ZxnmWYuCQJlyThkiRckixnB+ZxnmWYuCQJlyThkiRckixn39DUnTTPob1l4pIkXJKES5Jr3BV5nGc9Ji5JwiVJuCQJlyTL2YosYusxcUkSLknCJUm4JFnO9mDp2p6JS5JwSRIuScIlyXI2w5LL2MPrbrH/9T8zcUkSLknCJUm4JAmXJOGSJFyShEuScEly52yG91/sMXUnberLP6btvn4gTFyahEuScElyjbuH+dezrMXEJUm4JAmXJOGSZDk7ML+eswwTlyThkiRckoRL0sk4juPWh4DPMnFJEi5JwiVJuCQJlyThkiRckoRLknBJ+gsWfjWr1B4k1AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a random SNN data from the training dataset\n",
    "\n",
    "index = onp.random.randint(0, TRAIN_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"train\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_train_example.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c1eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACvklEQVR4nO3dsW0UURRA0VnkKsgsUwAhHVACLZBZyHVYljO3QAl0QEgBIGe08cnZCf7Ozsq+cE64+vJOcPW0T99eH8YYY4GYNy/9ALCFcEkSLknCJUm4JAmXJOGSJFyShEvS1ezB68f7Sz4HLMuyLM+3d1PnTFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJWn6v+68Vr8+PU2d+/j2/W7v+fPhw24/i21MXJKES5JwSRIuSfnlbNa33z+OXtu6sL378n3qnCXuckxckoRLknBJEi5J+eXs5uvno9dmb9PWFrYZe97CsY2JS5JwSRIuScIlKb+crTlnYZuxttStvSeXY+KSJFyShEuScEn6J5ezNecsbFM3ZQ8nPhBnMXFJEi5JwiVJuCQdxhhj5uD14/2ln+VVmFnYZn+t0d+cne759m7qnIlLknBJEi5J/80FxKyZi4q1z66z37XAPkxckoRLknBJEi5JlrMJfy9sa5cUN8vxUre2sLmU2IeJS5JwSRIuScIlyXK2wex3KFjELsfEJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSdBhjjJd+CDiViUuScEkSLknCJUm4JAmXJOGSJFyShEvSH/qDQYU+h8pUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a random SNN data from the test dataset\n",
    "\n",
    "index = onp.random.randint(0, TEST_NUM_DATA * NUM_SNN_DATA)\n",
    "print(index)\n",
    "spike = torch.load(\n",
    "    str(datasets_folder / \"event_based_data\" / \"test\" / f\"spike{int(index)}.pt\")\n",
    ")\n",
    "snn_animation(spike, str(outputs_dir / \"snn_test_example.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef06523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
